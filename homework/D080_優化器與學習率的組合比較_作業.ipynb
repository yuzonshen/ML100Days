{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AK19VSwuFAWc"
      },
      "source": [
        "# 請結合前面的知識與程式碼，比較不同的 optimizer 與 learning rate 組合對訓練的結果與影響\n",
        "### 常見的 optimizer 包含\n",
        "* SGD\n",
        "* RMSprop\n",
        "* AdaGrad\n",
        "* Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "X54O8RdeFAWf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from tensorflow import keras\n",
        "\n",
        "# 本作業可以不需使用 GPU, 將 GPU 設定為 \"無\" (若想使用可自行開啟)\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AHukY6M2FAWg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dece7ec-e69a-40d1-8a19-a4f98d4be7b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 13s 0us/step\n",
            "170508288/170498071 [==============================] - 13s 0us/step\n"
          ]
        }
      ],
      "source": [
        "train, test = keras.datasets.cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3hFzGh8UFAWh"
      },
      "outputs": [],
      "source": [
        "## 資料前處理\n",
        "def preproc_x(x, flatten=True):\n",
        "    x = x / 255.\n",
        "    if flatten:\n",
        "        x = x.reshape((len(x), -1))\n",
        "    return x\n",
        "\n",
        "def preproc_y(y, num_classes=10):\n",
        "    if y.shape[-1] == 1:\n",
        "        y = keras.utils.to_categorical(y, num_classes)\n",
        "    return y    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2gStzVFCFAWh"
      },
      "outputs": [],
      "source": [
        "x_train, y_train = train\n",
        "x_test, y_test = test\n",
        "\n",
        "# Preproc the inputs\n",
        "x_train = preproc_x(x_train)\n",
        "x_test = preproc_x(x_test)\n",
        "\n",
        "# Preprc the outputs\n",
        "y_train = preproc_y(y_train)\n",
        "y_test = preproc_y(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LsMheQnZFAWi"
      },
      "outputs": [],
      "source": [
        "def build_mlp(input_shape, output_units=10, num_neurons=[512, 256, 128]):\n",
        "    input_layer = keras.layers.Input(input_shape)\n",
        "    \n",
        "    for i, n_units in enumerate(num_neurons):\n",
        "        if i == 0:\n",
        "            x = keras.layers.Dense(units=n_units, activation=\"relu\", name=\"hidden_layer\"+str(i+1))(input_layer)\n",
        "        else:\n",
        "            x = keras.layers.Dense(units=n_units, activation=\"relu\", name=\"hidden_layer\"+str(i+1))(x)\n",
        "    \n",
        "    out = keras.layers.Dense(units=output_units, activation=\"softmax\", name=\"output\")(x)\n",
        "    \n",
        "    model = keras.models.Model(inputs=[input_layer], outputs=[out])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCHnpTXYFAWi"
      },
      "source": [
        "### 以同一模型, 分別驗證 SGD, Adam, Rmsprop, AdaGrad 的 accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Qa6CoHF6FAWj"
      },
      "outputs": [],
      "source": [
        "## 超參數設定\n",
        "LEARNING_RATE = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
        "#LEARNING_RATE = 0.001\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 256\n",
        "MOMENTUM = 0.95\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYhEd2piFAWk",
        "outputId": "a32590df-d49d-4321-cce2-50ea5c44949e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment with LR=0.1, optimizer:SGD\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 3072)]            0         \n",
            "                                                                 \n",
            " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
            "                                                                 \n",
            " hidden_layer2 (Dense)       (None, 256)               131328    \n",
            "                                                                 \n",
            " hidden_layer3 (Dense)       (None, 128)               32896     \n",
            "                                                                 \n",
            " output (Dense)              (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,738,890\n",
            "Trainable params: 1,738,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "196/196 [==============================] - 3s 6ms/step - loss: 2.3021 - accuracy: 0.1348 - val_loss: 2.3048 - val_accuracy: 0.1000\n",
            "Epoch 2/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3044 - accuracy: 0.0970 - val_loss: 2.3031 - val_accuracy: 0.1000\n",
            "Epoch 3/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3043 - accuracy: 0.0995 - val_loss: 2.3038 - val_accuracy: 0.1000\n",
            "Epoch 4/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3047 - accuracy: 0.0984 - val_loss: 2.3037 - val_accuracy: 0.1000\n",
            "Epoch 5/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3042 - accuracy: 0.0977 - val_loss: 2.3043 - val_accuracy: 0.1000\n",
            "Epoch 6/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3045 - accuracy: 0.0971 - val_loss: 2.3043 - val_accuracy: 0.1000\n",
            "Epoch 7/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3042 - accuracy: 0.1001 - val_loss: 2.3034 - val_accuracy: 0.1000\n",
            "Epoch 8/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3042 - accuracy: 0.1003 - val_loss: 2.3043 - val_accuracy: 0.1000\n",
            "Epoch 9/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3044 - accuracy: 0.0987 - val_loss: 2.3036 - val_accuracy: 0.1000\n",
            "Epoch 10/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3042 - accuracy: 0.0981 - val_loss: 2.3038 - val_accuracy: 0.1000\n",
            "Epoch 11/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3042 - accuracy: 0.0973 - val_loss: 2.3054 - val_accuracy: 0.1000\n",
            "Epoch 12/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3045 - accuracy: 0.0984 - val_loss: 2.3040 - val_accuracy: 0.1000\n",
            "Epoch 13/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3043 - accuracy: 0.0993 - val_loss: 2.3036 - val_accuracy: 0.1000\n",
            "Epoch 14/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3042 - accuracy: 0.1020 - val_loss: 2.3053 - val_accuracy: 0.1000\n",
            "Epoch 15/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3040 - accuracy: 0.0987 - val_loss: 2.3035 - val_accuracy: 0.1000\n",
            "Epoch 16/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3043 - accuracy: 0.0992 - val_loss: 2.3042 - val_accuracy: 0.1000\n",
            "Epoch 17/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3042 - accuracy: 0.0989 - val_loss: 2.3035 - val_accuracy: 0.1000\n",
            "Epoch 18/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3040 - accuracy: 0.0995 - val_loss: 2.3046 - val_accuracy: 0.1000\n",
            "Epoch 19/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3041 - accuracy: 0.1007 - val_loss: 2.3033 - val_accuracy: 0.1000\n",
            "Epoch 20/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3042 - accuracy: 0.0989 - val_loss: 2.3038 - val_accuracy: 0.1000\n",
            "Epoch 21/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3038 - accuracy: 0.1005 - val_loss: 2.3037 - val_accuracy: 0.1000\n",
            "Epoch 22/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3046 - accuracy: 0.0991 - val_loss: 2.3041 - val_accuracy: 0.1000\n",
            "Epoch 23/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3046 - accuracy: 0.0993 - val_loss: 2.3036 - val_accuracy: 0.1000\n",
            "Epoch 24/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3042 - accuracy: 0.0991 - val_loss: 2.3036 - val_accuracy: 0.1000\n",
            "Epoch 25/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3047 - accuracy: 0.0972 - val_loss: 2.3035 - val_accuracy: 0.1000\n",
            "Epoch 26/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3037 - accuracy: 0.1009 - val_loss: 2.3045 - val_accuracy: 0.1000\n",
            "Epoch 27/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3045 - accuracy: 0.1007 - val_loss: 2.3039 - val_accuracy: 0.1000\n",
            "Epoch 28/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3042 - accuracy: 0.0999 - val_loss: 2.3040 - val_accuracy: 0.1000\n",
            "Epoch 29/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3041 - accuracy: 0.1000 - val_loss: 2.3044 - val_accuracy: 0.1000\n",
            "Epoch 30/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3037 - accuracy: 0.1021 - val_loss: 2.3031 - val_accuracy: 0.1000\n",
            "Epoch 31/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3042 - accuracy: 0.0988 - val_loss: 2.3039 - val_accuracy: 0.1000\n",
            "Epoch 32/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3042 - accuracy: 0.1009 - val_loss: 2.3048 - val_accuracy: 0.1000\n",
            "Epoch 33/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3044 - accuracy: 0.1001 - val_loss: 2.3043 - val_accuracy: 0.1000\n",
            "Epoch 34/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3042 - accuracy: 0.0994 - val_loss: 2.3045 - val_accuracy: 0.1000\n",
            "Epoch 35/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3041 - accuracy: 0.1007 - val_loss: 2.3045 - val_accuracy: 0.1000\n",
            "Epoch 36/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3039 - accuracy: 0.1009 - val_loss: 2.3038 - val_accuracy: 0.1000\n",
            "Epoch 37/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3042 - accuracy: 0.0983 - val_loss: 2.3042 - val_accuracy: 0.1000\n",
            "Epoch 38/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3042 - accuracy: 0.0987 - val_loss: 2.3050 - val_accuracy: 0.1000\n",
            "Epoch 39/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3046 - accuracy: 0.0981 - val_loss: 2.3046 - val_accuracy: 0.1000\n",
            "Epoch 40/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3042 - accuracy: 0.1007 - val_loss: 2.3037 - val_accuracy: 0.1000\n",
            "Epoch 41/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3041 - accuracy: 0.0991 - val_loss: 2.3063 - val_accuracy: 0.1000\n",
            "Epoch 42/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3049 - accuracy: 0.1000 - val_loss: 2.3035 - val_accuracy: 0.1000\n",
            "Epoch 43/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3046 - accuracy: 0.0980 - val_loss: 2.3036 - val_accuracy: 0.1000\n",
            "Epoch 44/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3041 - accuracy: 0.1014 - val_loss: 2.3042 - val_accuracy: 0.1000\n",
            "Epoch 45/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3041 - accuracy: 0.1010 - val_loss: 2.3040 - val_accuracy: 0.1000\n",
            "Epoch 46/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3039 - accuracy: 0.0988 - val_loss: 2.3039 - val_accuracy: 0.1000\n",
            "Epoch 47/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3042 - accuracy: 0.0992 - val_loss: 2.3042 - val_accuracy: 0.1000\n",
            "Epoch 48/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3041 - accuracy: 0.0991 - val_loss: 2.3046 - val_accuracy: 0.1000\n",
            "Epoch 49/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3045 - accuracy: 0.0965 - val_loss: 2.3034 - val_accuracy: 0.1000\n",
            "Epoch 50/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3041 - accuracy: 0.0998 - val_loss: 2.3033 - val_accuracy: 0.1000\n",
            "Experiment with LR=0.1, optimizer:Adam\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 3072)]            0         \n",
            "                                                                 \n",
            " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
            "                                                                 \n",
            " hidden_layer2 (Dense)       (None, 256)               131328    \n",
            "                                                                 \n",
            " hidden_layer3 (Dense)       (None, 128)               32896     \n",
            "                                                                 \n",
            " output (Dense)              (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,738,890\n",
            "Trainable params: 1,738,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 286.6577 - accuracy: 0.1003 - val_loss: 2.3036 - val_accuracy: 0.1000\n",
            "Epoch 2/50\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 2.3038 - accuracy: 0.0986 - val_loss: 2.3036 - val_accuracy: 0.1000\n",
            "Epoch 3/50\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 2.3043 - accuracy: 0.1016 - val_loss: 2.3048 - val_accuracy: 0.1000\n",
            "Epoch 4/50\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 2.3049 - accuracy: 0.0989 - val_loss: 2.3055 - val_accuracy: 0.1000\n",
            "Epoch 5/50\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 2.3052 - accuracy: 0.0987 - val_loss: 2.3046 - val_accuracy: 0.1000\n",
            "Epoch 6/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3055 - accuracy: 0.1006 - val_loss: 2.3034 - val_accuracy: 0.1000\n",
            "Epoch 7/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3054 - accuracy: 0.1008 - val_loss: 2.3057 - val_accuracy: 0.1000\n",
            "Epoch 8/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3055 - accuracy: 0.0987 - val_loss: 2.3093 - val_accuracy: 0.1000\n",
            "Epoch 9/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3071 - accuracy: 0.0982 - val_loss: 2.3040 - val_accuracy: 0.1000\n",
            "Epoch 10/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3061 - accuracy: 0.0981 - val_loss: 2.3057 - val_accuracy: 0.1000\n",
            "Epoch 11/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3061 - accuracy: 0.0998 - val_loss: 2.3045 - val_accuracy: 0.1000\n",
            "Epoch 12/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3066 - accuracy: 0.0982 - val_loss: 2.3042 - val_accuracy: 0.1000\n",
            "Epoch 13/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3065 - accuracy: 0.0994 - val_loss: 2.3058 - val_accuracy: 0.1000\n",
            "Epoch 14/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3062 - accuracy: 0.0989 - val_loss: 2.3074 - val_accuracy: 0.1000\n",
            "Epoch 15/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3072 - accuracy: 0.0995 - val_loss: 2.3055 - val_accuracy: 0.1000\n",
            "Epoch 16/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3065 - accuracy: 0.0989 - val_loss: 2.3051 - val_accuracy: 0.1000\n",
            "Epoch 17/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3061 - accuracy: 0.0988 - val_loss: 2.3063 - val_accuracy: 0.1000\n",
            "Epoch 18/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3068 - accuracy: 0.0997 - val_loss: 2.3083 - val_accuracy: 0.1000\n",
            "Epoch 19/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3065 - accuracy: 0.1001 - val_loss: 2.3085 - val_accuracy: 0.1000\n",
            "Epoch 20/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3072 - accuracy: 0.0995 - val_loss: 2.3053 - val_accuracy: 0.1000\n",
            "Epoch 21/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3062 - accuracy: 0.1006 - val_loss: 2.3040 - val_accuracy: 0.1000\n",
            "Epoch 22/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3066 - accuracy: 0.0999 - val_loss: 2.3061 - val_accuracy: 0.1000\n",
            "Epoch 23/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3064 - accuracy: 0.0986 - val_loss: 2.3071 - val_accuracy: 0.1000\n",
            "Epoch 24/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3070 - accuracy: 0.1004 - val_loss: 2.3083 - val_accuracy: 0.1000\n",
            "Epoch 25/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3072 - accuracy: 0.0992 - val_loss: 2.3048 - val_accuracy: 0.1000\n",
            "Epoch 26/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3076 - accuracy: 0.1008 - val_loss: 2.3047 - val_accuracy: 0.1000\n",
            "Epoch 27/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3070 - accuracy: 0.0969 - val_loss: 2.3064 - val_accuracy: 0.1000\n",
            "Epoch 28/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3070 - accuracy: 0.1013 - val_loss: 2.3048 - val_accuracy: 0.1000\n",
            "Epoch 29/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3072 - accuracy: 0.1006 - val_loss: 2.3078 - val_accuracy: 0.1000\n",
            "Epoch 30/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3070 - accuracy: 0.0994 - val_loss: 2.3081 - val_accuracy: 0.1000\n",
            "Epoch 31/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3058 - accuracy: 0.1021 - val_loss: 2.3112 - val_accuracy: 0.1000\n",
            "Epoch 32/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3067 - accuracy: 0.1016 - val_loss: 2.3040 - val_accuracy: 0.1000\n",
            "Epoch 33/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3065 - accuracy: 0.1004 - val_loss: 2.3103 - val_accuracy: 0.1000\n",
            "Epoch 34/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3072 - accuracy: 0.0996 - val_loss: 2.3089 - val_accuracy: 0.1000\n",
            "Epoch 35/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3068 - accuracy: 0.0989 - val_loss: 2.3104 - val_accuracy: 0.1000\n",
            "Epoch 36/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3072 - accuracy: 0.0991 - val_loss: 2.3060 - val_accuracy: 0.1000\n",
            "Epoch 37/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3071 - accuracy: 0.0983 - val_loss: 2.3068 - val_accuracy: 0.1000\n",
            "Epoch 38/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3074 - accuracy: 0.0979 - val_loss: 2.3067 - val_accuracy: 0.1000\n",
            "Epoch 39/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3071 - accuracy: 0.0990 - val_loss: 2.3071 - val_accuracy: 0.1000\n",
            "Epoch 40/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3072 - accuracy: 0.0990 - val_loss: 2.3078 - val_accuracy: 0.1000\n",
            "Epoch 41/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3069 - accuracy: 0.0999 - val_loss: 2.3089 - val_accuracy: 0.1000\n",
            "Epoch 42/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3067 - accuracy: 0.0983 - val_loss: 2.3050 - val_accuracy: 0.1000\n",
            "Epoch 43/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3066 - accuracy: 0.1006 - val_loss: 2.3083 - val_accuracy: 0.1000\n",
            "Epoch 44/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3074 - accuracy: 0.0989 - val_loss: 2.3056 - val_accuracy: 0.1000\n",
            "Epoch 45/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3074 - accuracy: 0.0997 - val_loss: 2.3067 - val_accuracy: 0.1000\n",
            "Epoch 46/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3068 - accuracy: 0.0973 - val_loss: 2.3068 - val_accuracy: 0.1000\n",
            "Epoch 47/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3066 - accuracy: 0.1010 - val_loss: 2.3076 - val_accuracy: 0.1000\n",
            "Epoch 48/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3073 - accuracy: 0.1017 - val_loss: 2.3047 - val_accuracy: 0.1000\n",
            "Epoch 49/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3063 - accuracy: 0.0985 - val_loss: 2.3074 - val_accuracy: 0.1000\n",
            "Epoch 50/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.3073 - accuracy: 0.0979 - val_loss: 2.3059 - val_accuracy: 0.1000\n",
            "Experiment with LR=0.1, optimizer:RMSprop\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 3072)]            0         \n",
            "                                                                 \n",
            " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
            "                                                                 \n",
            " hidden_layer2 (Dense)       (None, 256)               131328    \n",
            "                                                                 \n",
            " hidden_layer3 (Dense)       (None, 128)               32896     \n",
            "                                                                 \n",
            " output (Dense)              (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,738,890\n",
            "Trainable params: 1,738,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "196/196 [==============================] - 2s 7ms/step - loss: 22731.5684 - accuracy: 0.1012 - val_loss: 2.3093 - val_accuracy: 0.1000\n",
            "Epoch 2/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 399.2586 - accuracy: 0.1002 - val_loss: 1008.4645 - val_accuracy: 0.1000\n",
            "Epoch 3/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 25.6454 - accuracy: 0.1010 - val_loss: 2.3120 - val_accuracy: 0.1000\n",
            "Epoch 4/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3077 - accuracy: 0.1004 - val_loss: 2.3107 - val_accuracy: 0.1000\n",
            "Epoch 5/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3079 - accuracy: 0.0983 - val_loss: 2.3093 - val_accuracy: 0.1000\n",
            "Epoch 6/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3074 - accuracy: 0.0994 - val_loss: 2.3106 - val_accuracy: 0.1000\n",
            "Epoch 7/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3080 - accuracy: 0.0993 - val_loss: 2.3082 - val_accuracy: 0.1000\n",
            "Epoch 8/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3079 - accuracy: 0.1009 - val_loss: 2.3258 - val_accuracy: 0.1000\n",
            "Epoch 9/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3080 - accuracy: 0.0993 - val_loss: 2.3142 - val_accuracy: 0.1000\n",
            "Epoch 10/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3080 - accuracy: 0.0999 - val_loss: 2.3090 - val_accuracy: 0.1000\n",
            "Epoch 11/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3076 - accuracy: 0.1009 - val_loss: 2.3097 - val_accuracy: 0.1000\n",
            "Epoch 12/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3077 - accuracy: 0.0987 - val_loss: 2.3096 - val_accuracy: 0.1000\n",
            "Epoch 13/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3077 - accuracy: 0.0992 - val_loss: 2.3114 - val_accuracy: 0.1000\n",
            "Epoch 14/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3079 - accuracy: 0.0997 - val_loss: 2.3101 - val_accuracy: 0.1000\n",
            "Epoch 15/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3077 - accuracy: 0.1016 - val_loss: 2.3105 - val_accuracy: 0.1000\n",
            "Epoch 16/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3080 - accuracy: 0.0993 - val_loss: 2.3112 - val_accuracy: 0.1000\n",
            "Epoch 17/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3078 - accuracy: 0.1021 - val_loss: 2.3122 - val_accuracy: 0.1000\n",
            "Epoch 18/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3075 - accuracy: 0.1007 - val_loss: 2.3137 - val_accuracy: 0.1000\n",
            "Epoch 19/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3084 - accuracy: 0.0969 - val_loss: 2.3126 - val_accuracy: 0.1000\n",
            "Epoch 20/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3075 - accuracy: 0.1014 - val_loss: 2.3190 - val_accuracy: 0.1000\n",
            "Epoch 21/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3080 - accuracy: 0.0988 - val_loss: 2.3192 - val_accuracy: 0.1000\n",
            "Epoch 22/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3079 - accuracy: 0.1005 - val_loss: 2.3128 - val_accuracy: 0.1000\n",
            "Epoch 23/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3077 - accuracy: 0.0985 - val_loss: 2.3156 - val_accuracy: 0.1000\n",
            "Epoch 24/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3079 - accuracy: 0.0982 - val_loss: 2.3183 - val_accuracy: 0.1000\n",
            "Epoch 25/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3078 - accuracy: 0.0981 - val_loss: 2.3217 - val_accuracy: 0.1000\n",
            "Epoch 26/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3082 - accuracy: 0.1005 - val_loss: 2.3155 - val_accuracy: 0.1000\n",
            "Epoch 27/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3085 - accuracy: 0.0972 - val_loss: 2.3075 - val_accuracy: 0.1000\n",
            "Epoch 28/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3079 - accuracy: 0.0988 - val_loss: 2.3118 - val_accuracy: 0.1000\n",
            "Epoch 29/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3083 - accuracy: 0.0997 - val_loss: 2.3122 - val_accuracy: 0.1000\n",
            "Epoch 30/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3078 - accuracy: 0.0995 - val_loss: 2.3085 - val_accuracy: 0.1000\n",
            "Epoch 31/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3078 - accuracy: 0.0991 - val_loss: 2.3108 - val_accuracy: 0.1000\n",
            "Epoch 32/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3080 - accuracy: 0.0995 - val_loss: 2.3109 - val_accuracy: 0.1000\n",
            "Epoch 33/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3076 - accuracy: 0.0988 - val_loss: 2.3165 - val_accuracy: 0.1000\n",
            "Epoch 34/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3081 - accuracy: 0.1007 - val_loss: 2.3158 - val_accuracy: 0.1000\n",
            "Epoch 35/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3078 - accuracy: 0.1012 - val_loss: 2.3126 - val_accuracy: 0.1000\n",
            "Epoch 36/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3073 - accuracy: 0.1020 - val_loss: 2.3073 - val_accuracy: 0.1000\n",
            "Epoch 37/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3080 - accuracy: 0.0975 - val_loss: 2.3153 - val_accuracy: 0.1000\n",
            "Epoch 38/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3078 - accuracy: 0.0995 - val_loss: 2.3089 - val_accuracy: 0.1000\n",
            "Epoch 39/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3079 - accuracy: 0.0998 - val_loss: 2.3242 - val_accuracy: 0.1000\n",
            "Epoch 40/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3081 - accuracy: 0.0993 - val_loss: 2.3074 - val_accuracy: 0.1000\n",
            "Epoch 41/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3080 - accuracy: 0.0989 - val_loss: 2.3070 - val_accuracy: 0.1000\n",
            "Epoch 42/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3076 - accuracy: 0.1002 - val_loss: 2.3093 - val_accuracy: 0.1000\n",
            "Epoch 43/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3084 - accuracy: 0.0965 - val_loss: 2.3109 - val_accuracy: 0.1000\n",
            "Epoch 44/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3077 - accuracy: 0.1002 - val_loss: 2.3074 - val_accuracy: 0.1000\n",
            "Epoch 45/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3076 - accuracy: 0.1010 - val_loss: 2.3077 - val_accuracy: 0.1000\n",
            "Epoch 46/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3077 - accuracy: 0.0996 - val_loss: 2.3164 - val_accuracy: 0.1000\n",
            "Epoch 47/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3078 - accuracy: 0.1015 - val_loss: 2.3095 - val_accuracy: 0.1000\n",
            "Epoch 48/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3078 - accuracy: 0.1012 - val_loss: 2.3153 - val_accuracy: 0.1000\n",
            "Epoch 49/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3080 - accuracy: 0.0987 - val_loss: 2.3104 - val_accuracy: 0.1000\n",
            "Epoch 50/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.3081 - accuracy: 0.0990 - val_loss: 2.3101 - val_accuracy: 0.1000\n",
            "Experiment with LR=0.1, optimizer:Adagrad\n",
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 3072)]            0         \n",
            "                                                                 \n",
            " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
            "                                                                 \n",
            " hidden_layer2 (Dense)       (None, 256)               131328    \n",
            "                                                                 \n",
            " hidden_layer3 (Dense)       (None, 128)               32896     \n",
            "                                                                 \n",
            " output (Dense)              (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,738,890\n",
            "Trainable params: 1,738,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "196/196 [==============================] - 2s 6ms/step - loss: 2.2264 - accuracy: 0.1726 - val_loss: 2.1777 - val_accuracy: 0.2275\n",
            "Epoch 2/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 2.0093 - accuracy: 0.2624 - val_loss: 1.9559 - val_accuracy: 0.2913\n",
            "Epoch 3/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 1.8659 - accuracy: 0.3244 - val_loss: 1.9337 - val_accuracy: 0.3242\n",
            "Epoch 4/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 1.7988 - accuracy: 0.3508 - val_loss: 1.7463 - val_accuracy: 0.3675\n",
            "Epoch 5/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 1.7288 - accuracy: 0.3798 - val_loss: 1.7802 - val_accuracy: 0.3608\n",
            "Epoch 6/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.6956 - accuracy: 0.3916 - val_loss: 1.7091 - val_accuracy: 0.3974\n",
            "Epoch 7/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 1.6562 - accuracy: 0.4074 - val_loss: 1.7611 - val_accuracy: 0.3651\n",
            "Epoch 8/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.6084 - accuracy: 0.4234 - val_loss: 1.9919 - val_accuracy: 0.3329\n",
            "Epoch 9/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 1.5823 - accuracy: 0.4334 - val_loss: 1.6450 - val_accuracy: 0.4211\n",
            "Epoch 10/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.5499 - accuracy: 0.4459 - val_loss: 1.5753 - val_accuracy: 0.4361\n",
            "Epoch 11/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.5163 - accuracy: 0.4556 - val_loss: 1.6745 - val_accuracy: 0.4093\n",
            "Epoch 12/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.5003 - accuracy: 0.4616 - val_loss: 1.6160 - val_accuracy: 0.4232\n",
            "Epoch 13/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.4642 - accuracy: 0.4713 - val_loss: 1.6657 - val_accuracy: 0.4158\n",
            "Epoch 14/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.4468 - accuracy: 0.4821 - val_loss: 1.5047 - val_accuracy: 0.4617\n",
            "Epoch 15/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.4205 - accuracy: 0.4919 - val_loss: 1.5736 - val_accuracy: 0.4394\n",
            "Epoch 16/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.4000 - accuracy: 0.4981 - val_loss: 1.4748 - val_accuracy: 0.4709\n",
            "Epoch 17/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.3786 - accuracy: 0.5054 - val_loss: 1.5191 - val_accuracy: 0.4600\n",
            "Epoch 18/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.3591 - accuracy: 0.5142 - val_loss: 1.5429 - val_accuracy: 0.4485\n",
            "Epoch 19/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 1.3372 - accuracy: 0.5203 - val_loss: 1.6058 - val_accuracy: 0.4398\n",
            "Epoch 20/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.3209 - accuracy: 0.5258 - val_loss: 1.5416 - val_accuracy: 0.4654\n",
            "Epoch 21/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 1.3022 - accuracy: 0.5347 - val_loss: 1.5661 - val_accuracy: 0.4471\n",
            "Epoch 22/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 1.2834 - accuracy: 0.5399 - val_loss: 1.4835 - val_accuracy: 0.4827\n",
            "Epoch 23/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 1.2588 - accuracy: 0.5483 - val_loss: 1.4594 - val_accuracy: 0.4835\n",
            "Epoch 24/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.2385 - accuracy: 0.5559 - val_loss: 1.6383 - val_accuracy: 0.4429\n",
            "Epoch 25/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.2302 - accuracy: 0.5578 - val_loss: 1.5095 - val_accuracy: 0.4695\n",
            "Epoch 26/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.2058 - accuracy: 0.5680 - val_loss: 1.5405 - val_accuracy: 0.4692\n",
            "Epoch 27/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.1936 - accuracy: 0.5705 - val_loss: 1.6095 - val_accuracy: 0.4361\n",
            "Epoch 28/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.1652 - accuracy: 0.5816 - val_loss: 1.5306 - val_accuracy: 0.4697\n",
            "Epoch 29/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.1515 - accuracy: 0.5867 - val_loss: 1.5116 - val_accuracy: 0.4907\n",
            "Epoch 30/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.1303 - accuracy: 0.5933 - val_loss: 1.7398 - val_accuracy: 0.4367\n",
            "Epoch 31/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.1249 - accuracy: 0.5979 - val_loss: 1.7534 - val_accuracy: 0.4364\n",
            "Epoch 32/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.1042 - accuracy: 0.6028 - val_loss: 1.6275 - val_accuracy: 0.4486\n",
            "Epoch 33/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.0829 - accuracy: 0.6117 - val_loss: 1.5244 - val_accuracy: 0.4711\n",
            "Epoch 34/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.0635 - accuracy: 0.6189 - val_loss: 1.4671 - val_accuracy: 0.4970\n",
            "Epoch 35/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.0377 - accuracy: 0.6260 - val_loss: 1.5843 - val_accuracy: 0.4715\n",
            "Epoch 36/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.0277 - accuracy: 0.6291 - val_loss: 1.6508 - val_accuracy: 0.4753\n",
            "Epoch 37/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.0101 - accuracy: 0.6379 - val_loss: 1.6506 - val_accuracy: 0.4566\n",
            "Epoch 38/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.9874 - accuracy: 0.6443 - val_loss: 1.6126 - val_accuracy: 0.4698\n",
            "Epoch 39/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.9833 - accuracy: 0.6438 - val_loss: 1.5119 - val_accuracy: 0.4962\n",
            "Epoch 40/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 0.9621 - accuracy: 0.6553 - val_loss: 1.6958 - val_accuracy: 0.4379\n",
            "Epoch 41/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.9340 - accuracy: 0.6641 - val_loss: 1.6713 - val_accuracy: 0.4685\n",
            "Epoch 42/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 0.9247 - accuracy: 0.6664 - val_loss: 1.6999 - val_accuracy: 0.4768\n",
            "Epoch 43/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.9028 - accuracy: 0.6744 - val_loss: 1.7446 - val_accuracy: 0.4402\n",
            "Epoch 44/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.8941 - accuracy: 0.6792 - val_loss: 1.6296 - val_accuracy: 0.4933\n",
            "Epoch 45/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.8739 - accuracy: 0.6853 - val_loss: 1.7106 - val_accuracy: 0.4697\n",
            "Epoch 46/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.8582 - accuracy: 0.6905 - val_loss: 1.6063 - val_accuracy: 0.5044\n",
            "Epoch 47/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.8359 - accuracy: 0.7004 - val_loss: 1.7243 - val_accuracy: 0.4801\n",
            "Epoch 48/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.8258 - accuracy: 0.7010 - val_loss: 1.6835 - val_accuracy: 0.4985\n",
            "Epoch 49/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 0.8133 - accuracy: 0.7041 - val_loss: 1.8086 - val_accuracy: 0.4507\n",
            "Epoch 50/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.7949 - accuracy: 0.7146 - val_loss: 1.6813 - val_accuracy: 0.4969\n",
            "Experiment with LR=0.01, optimizer:SGD\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 3072)]            0         \n",
            "                                                                 \n",
            " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
            "                                                                 \n",
            " hidden_layer2 (Dense)       (None, 256)               131328    \n",
            "                                                                 \n",
            " hidden_layer3 (Dense)       (None, 128)               32896     \n",
            "                                                                 \n",
            " output (Dense)              (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,738,890\n",
            "Trainable params: 1,738,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "196/196 [==============================] - 2s 7ms/step - loss: 1.8341 - accuracy: 0.3444 - val_loss: 1.7399 - val_accuracy: 0.3742\n",
            "Epoch 2/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.6090 - accuracy: 0.4307 - val_loss: 1.6638 - val_accuracy: 0.3997\n",
            "Epoch 3/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 1.5184 - accuracy: 0.4615 - val_loss: 1.5387 - val_accuracy: 0.4581\n",
            "Epoch 4/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.4628 - accuracy: 0.4822 - val_loss: 1.5356 - val_accuracy: 0.4566\n",
            "Epoch 5/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.4133 - accuracy: 0.4971 - val_loss: 1.4678 - val_accuracy: 0.4738\n",
            "Epoch 6/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.3746 - accuracy: 0.5094 - val_loss: 1.4954 - val_accuracy: 0.4746\n",
            "Epoch 7/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.3413 - accuracy: 0.5225 - val_loss: 1.5049 - val_accuracy: 0.4742\n",
            "Epoch 8/50\n",
            "196/196 [==============================] - 1s 5ms/step - loss: 1.3064 - accuracy: 0.5344 - val_loss: 1.4029 - val_accuracy: 0.4990\n",
            "Epoch 9/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.2746 - accuracy: 0.5479 - val_loss: 1.5625 - val_accuracy: 0.4651\n",
            "Epoch 10/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.2415 - accuracy: 0.5587 - val_loss: 1.3447 - val_accuracy: 0.5172\n",
            "Epoch 11/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.2116 - accuracy: 0.5686 - val_loss: 1.4711 - val_accuracy: 0.4990\n",
            "Epoch 12/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.1836 - accuracy: 0.5785 - val_loss: 1.3587 - val_accuracy: 0.5202\n",
            "Epoch 13/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.1573 - accuracy: 0.5885 - val_loss: 1.4100 - val_accuracy: 0.5172\n",
            "Epoch 14/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.1299 - accuracy: 0.5969 - val_loss: 1.4138 - val_accuracy: 0.5091\n",
            "Epoch 15/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.1001 - accuracy: 0.6084 - val_loss: 1.3731 - val_accuracy: 0.5148\n",
            "Epoch 16/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.0785 - accuracy: 0.6178 - val_loss: 1.3791 - val_accuracy: 0.5180\n",
            "Epoch 17/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.0596 - accuracy: 0.6226 - val_loss: 1.3757 - val_accuracy: 0.5231\n",
            "Epoch 18/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.0308 - accuracy: 0.6349 - val_loss: 1.4352 - val_accuracy: 0.5055\n",
            "Epoch 19/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.0187 - accuracy: 0.6352 - val_loss: 1.3512 - val_accuracy: 0.5353\n",
            "Epoch 20/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.9863 - accuracy: 0.6475 - val_loss: 1.4324 - val_accuracy: 0.5222\n",
            "Epoch 21/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.9561 - accuracy: 0.6604 - val_loss: 1.3771 - val_accuracy: 0.5328\n",
            "Epoch 22/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.9363 - accuracy: 0.6670 - val_loss: 1.3989 - val_accuracy: 0.5283\n",
            "Epoch 23/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.9165 - accuracy: 0.6713 - val_loss: 1.5786 - val_accuracy: 0.5031\n",
            "Epoch 24/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.8911 - accuracy: 0.6817 - val_loss: 1.4262 - val_accuracy: 0.5316\n",
            "Epoch 25/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.8644 - accuracy: 0.6914 - val_loss: 1.3992 - val_accuracy: 0.5409\n",
            "Epoch 26/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.8402 - accuracy: 0.7019 - val_loss: 1.4330 - val_accuracy: 0.5315\n",
            "Epoch 27/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.8198 - accuracy: 0.7066 - val_loss: 1.4418 - val_accuracy: 0.5354\n",
            "Epoch 28/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.7977 - accuracy: 0.7132 - val_loss: 1.5085 - val_accuracy: 0.5372\n",
            "Epoch 29/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.7697 - accuracy: 0.7269 - val_loss: 1.4738 - val_accuracy: 0.5358\n",
            "Epoch 30/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.7507 - accuracy: 0.7306 - val_loss: 1.5305 - val_accuracy: 0.5291\n",
            "Epoch 31/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.7274 - accuracy: 0.7412 - val_loss: 1.6094 - val_accuracy: 0.5193\n",
            "Epoch 32/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.6976 - accuracy: 0.7493 - val_loss: 1.5568 - val_accuracy: 0.5349\n",
            "Epoch 33/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.6792 - accuracy: 0.7573 - val_loss: 1.6337 - val_accuracy: 0.5405\n",
            "Epoch 34/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.6663 - accuracy: 0.7610 - val_loss: 1.6019 - val_accuracy: 0.5434\n",
            "Epoch 35/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.6411 - accuracy: 0.7698 - val_loss: 1.5992 - val_accuracy: 0.5385\n",
            "Epoch 36/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.6177 - accuracy: 0.7779 - val_loss: 1.7174 - val_accuracy: 0.5353\n",
            "Epoch 37/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.6019 - accuracy: 0.7837 - val_loss: 1.6408 - val_accuracy: 0.5358\n",
            "Epoch 38/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.5839 - accuracy: 0.7896 - val_loss: 1.7292 - val_accuracy: 0.5353\n",
            "Epoch 39/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.5574 - accuracy: 0.7981 - val_loss: 1.8368 - val_accuracy: 0.5275\n",
            "Epoch 40/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.5360 - accuracy: 0.8091 - val_loss: 1.9394 - val_accuracy: 0.5120\n",
            "Epoch 41/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.5163 - accuracy: 0.8140 - val_loss: 1.8974 - val_accuracy: 0.5212\n",
            "Epoch 42/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.5071 - accuracy: 0.8185 - val_loss: 1.8823 - val_accuracy: 0.5214\n",
            "Epoch 43/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.4867 - accuracy: 0.8230 - val_loss: 1.9510 - val_accuracy: 0.5203\n",
            "Epoch 44/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.4712 - accuracy: 0.8304 - val_loss: 1.9058 - val_accuracy: 0.5253\n",
            "Epoch 45/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.4578 - accuracy: 0.8350 - val_loss: 2.0347 - val_accuracy: 0.5073\n",
            "Epoch 46/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.4415 - accuracy: 0.8407 - val_loss: 2.1492 - val_accuracy: 0.5227\n",
            "Epoch 47/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.4356 - accuracy: 0.8426 - val_loss: 2.1417 - val_accuracy: 0.5237\n",
            "Epoch 48/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.4070 - accuracy: 0.8541 - val_loss: 2.1715 - val_accuracy: 0.5145\n",
            "Epoch 49/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.4041 - accuracy: 0.8544 - val_loss: 2.1986 - val_accuracy: 0.5268\n",
            "Epoch 50/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.3970 - accuracy: 0.8558 - val_loss: 2.2523 - val_accuracy: 0.5191\n",
            "Experiment with LR=0.01, optimizer:Adam\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 3072)]            0         \n",
            "                                                                 \n",
            " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
            "                                                                 \n",
            " hidden_layer2 (Dense)       (None, 256)               131328    \n",
            "                                                                 \n",
            " hidden_layer3 (Dense)       (None, 128)               32896     \n",
            "                                                                 \n",
            " output (Dense)              (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,738,890\n",
            "Trainable params: 1,738,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "196/196 [==============================] - 2s 7ms/step - loss: 3.1650 - accuracy: 0.1627 - val_loss: 2.1481 - val_accuracy: 0.1610\n",
            "Epoch 2/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0907 - accuracy: 0.1777 - val_loss: 2.1044 - val_accuracy: 0.1690\n",
            "Epoch 3/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0806 - accuracy: 0.1829 - val_loss: 2.0581 - val_accuracy: 0.1849\n",
            "Epoch 4/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0743 - accuracy: 0.1847 - val_loss: 2.1198 - val_accuracy: 0.1662\n",
            "Epoch 5/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0786 - accuracy: 0.1819 - val_loss: 2.0598 - val_accuracy: 0.1881\n",
            "Epoch 6/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0782 - accuracy: 0.1812 - val_loss: 2.1364 - val_accuracy: 0.1633\n",
            "Epoch 7/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0835 - accuracy: 0.1843 - val_loss: 2.0598 - val_accuracy: 0.1886\n",
            "Epoch 8/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.0681 - accuracy: 0.1839 - val_loss: 2.0989 - val_accuracy: 0.1821\n",
            "Epoch 9/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0706 - accuracy: 0.1827 - val_loss: 2.0820 - val_accuracy: 0.1857\n",
            "Epoch 10/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0796 - accuracy: 0.1838 - val_loss: 2.0600 - val_accuracy: 0.1804\n",
            "Epoch 11/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0826 - accuracy: 0.1790 - val_loss: 2.0566 - val_accuracy: 0.1863\n",
            "Epoch 12/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0812 - accuracy: 0.1804 - val_loss: 2.0766 - val_accuracy: 0.1805\n",
            "Epoch 13/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0798 - accuracy: 0.1843 - val_loss: 2.0620 - val_accuracy: 0.1834\n",
            "Epoch 14/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0738 - accuracy: 0.1821 - val_loss: 2.0570 - val_accuracy: 0.1924\n",
            "Epoch 15/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0785 - accuracy: 0.1824 - val_loss: 2.0720 - val_accuracy: 0.1838\n",
            "Epoch 16/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0698 - accuracy: 0.1855 - val_loss: 2.0558 - val_accuracy: 0.1925\n",
            "Epoch 17/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0807 - accuracy: 0.1848 - val_loss: 2.0553 - val_accuracy: 0.1901\n",
            "Epoch 18/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0668 - accuracy: 0.1894 - val_loss: 2.0741 - val_accuracy: 0.1854\n",
            "Epoch 19/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0695 - accuracy: 0.1851 - val_loss: 2.0809 - val_accuracy: 0.1935\n",
            "Epoch 20/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0716 - accuracy: 0.1869 - val_loss: 2.0527 - val_accuracy: 0.1891\n",
            "Epoch 21/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0697 - accuracy: 0.1823 - val_loss: 2.0548 - val_accuracy: 0.1915\n",
            "Epoch 22/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0788 - accuracy: 0.1837 - val_loss: 2.0641 - val_accuracy: 0.1886\n",
            "Epoch 23/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0637 - accuracy: 0.1891 - val_loss: 2.0478 - val_accuracy: 0.1880\n",
            "Epoch 24/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0659 - accuracy: 0.1888 - val_loss: 2.0574 - val_accuracy: 0.1905\n",
            "Epoch 25/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0775 - accuracy: 0.1860 - val_loss: 2.0566 - val_accuracy: 0.1912\n",
            "Epoch 26/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0668 - accuracy: 0.1878 - val_loss: 2.0863 - val_accuracy: 0.1854\n",
            "Epoch 27/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0653 - accuracy: 0.1870 - val_loss: 2.1940 - val_accuracy: 0.1608\n",
            "Epoch 28/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0750 - accuracy: 0.1841 - val_loss: 2.0574 - val_accuracy: 0.1843\n",
            "Epoch 29/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0889 - accuracy: 0.1828 - val_loss: 2.0968 - val_accuracy: 0.1862\n",
            "Epoch 30/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0801 - accuracy: 0.1866 - val_loss: 2.0555 - val_accuracy: 0.1879\n",
            "Epoch 31/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0808 - accuracy: 0.1839 - val_loss: 2.0730 - val_accuracy: 0.1876\n",
            "Epoch 32/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0987 - accuracy: 0.1786 - val_loss: 2.1247 - val_accuracy: 0.1771\n",
            "Epoch 33/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0649 - accuracy: 0.1890 - val_loss: 2.0617 - val_accuracy: 0.1955\n",
            "Epoch 34/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0605 - accuracy: 0.1873 - val_loss: 2.0604 - val_accuracy: 0.1921\n",
            "Epoch 35/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0626 - accuracy: 0.1862 - val_loss: 2.0739 - val_accuracy: 0.1889\n",
            "Epoch 36/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0627 - accuracy: 0.1870 - val_loss: 2.0534 - val_accuracy: 0.1864\n",
            "Epoch 37/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0741 - accuracy: 0.1848 - val_loss: 2.0533 - val_accuracy: 0.1902\n",
            "Epoch 38/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0663 - accuracy: 0.1881 - val_loss: 2.0549 - val_accuracy: 0.1858\n",
            "Epoch 39/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0895 - accuracy: 0.1786 - val_loss: 2.0585 - val_accuracy: 0.1839\n",
            "Epoch 40/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0688 - accuracy: 0.1848 - val_loss: 2.0573 - val_accuracy: 0.1828\n",
            "Epoch 41/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0706 - accuracy: 0.1864 - val_loss: 2.0560 - val_accuracy: 0.1934\n",
            "Epoch 42/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0739 - accuracy: 0.1851 - val_loss: 2.0904 - val_accuracy: 0.1808\n",
            "Epoch 43/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0729 - accuracy: 0.1846 - val_loss: 2.0813 - val_accuracy: 0.1884\n",
            "Epoch 44/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0904 - accuracy: 0.1781 - val_loss: 2.0598 - val_accuracy: 0.1804\n",
            "Epoch 45/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0637 - accuracy: 0.1854 - val_loss: 2.0536 - val_accuracy: 0.1868\n",
            "Epoch 46/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0666 - accuracy: 0.1824 - val_loss: 2.0538 - val_accuracy: 0.1876\n",
            "Epoch 47/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0697 - accuracy: 0.1876 - val_loss: 2.0552 - val_accuracy: 0.1902\n",
            "Epoch 48/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0704 - accuracy: 0.1844 - val_loss: 2.0531 - val_accuracy: 0.1854\n",
            "Epoch 49/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.1128 - accuracy: 0.1750 - val_loss: 2.0953 - val_accuracy: 0.1697\n",
            "Epoch 50/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0917 - accuracy: 0.1798 - val_loss: 2.0640 - val_accuracy: 0.1807\n",
            "Experiment with LR=0.01, optimizer:RMSprop\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 3072)]            0         \n",
            "                                                                 \n",
            " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
            "                                                                 \n",
            " hidden_layer2 (Dense)       (None, 256)               131328    \n",
            "                                                                 \n",
            " hidden_layer3 (Dense)       (None, 128)               32896     \n",
            "                                                                 \n",
            " output (Dense)              (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,738,890\n",
            "Trainable params: 1,738,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 10.0775 - accuracy: 0.1369 - val_loss: 2.1746 - val_accuracy: 0.1414\n",
            "Epoch 2/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.1328 - accuracy: 0.1770 - val_loss: 2.2654 - val_accuracy: 0.1564\n",
            "Epoch 3/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.0805 - accuracy: 0.2003 - val_loss: 2.1306 - val_accuracy: 0.1911\n",
            "Epoch 4/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.0420 - accuracy: 0.2169 - val_loss: 1.9755 - val_accuracy: 0.2502\n",
            "Epoch 5/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.9822 - accuracy: 0.2573 - val_loss: 2.0858 - val_accuracy: 0.1943\n",
            "Epoch 6/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.9491 - accuracy: 0.2761 - val_loss: 1.9527 - val_accuracy: 0.2678\n",
            "Epoch 7/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.9269 - accuracy: 0.2850 - val_loss: 1.8894 - val_accuracy: 0.2894\n",
            "Epoch 8/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.9122 - accuracy: 0.2922 - val_loss: 1.9748 - val_accuracy: 0.2664\n",
            "Epoch 9/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.9058 - accuracy: 0.2922 - val_loss: 1.9127 - val_accuracy: 0.2888\n",
            "Epoch 10/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.8960 - accuracy: 0.2944 - val_loss: 1.8971 - val_accuracy: 0.2906\n",
            "Epoch 11/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.8906 - accuracy: 0.3002 - val_loss: 1.9328 - val_accuracy: 0.2871\n",
            "Epoch 12/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.8872 - accuracy: 0.3033 - val_loss: 1.9924 - val_accuracy: 0.2691\n",
            "Epoch 13/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.8726 - accuracy: 0.3054 - val_loss: 1.8980 - val_accuracy: 0.2904\n",
            "Epoch 14/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.8702 - accuracy: 0.3096 - val_loss: 1.8957 - val_accuracy: 0.2981\n",
            "Epoch 15/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.8621 - accuracy: 0.3084 - val_loss: 1.9237 - val_accuracy: 0.2905\n",
            "Epoch 16/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.8536 - accuracy: 0.3161 - val_loss: 2.0992 - val_accuracy: 0.2430\n",
            "Epoch 17/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.8544 - accuracy: 0.3130 - val_loss: 2.0771 - val_accuracy: 0.2513\n",
            "Epoch 18/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.8498 - accuracy: 0.3171 - val_loss: 1.9245 - val_accuracy: 0.2931\n",
            "Epoch 19/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.8395 - accuracy: 0.3193 - val_loss: 1.8372 - val_accuracy: 0.3220\n",
            "Epoch 20/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.8414 - accuracy: 0.3215 - val_loss: 1.9066 - val_accuracy: 0.3029\n",
            "Epoch 21/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.8343 - accuracy: 0.3200 - val_loss: 1.8285 - val_accuracy: 0.3143\n",
            "Epoch 22/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.8326 - accuracy: 0.3197 - val_loss: 2.0727 - val_accuracy: 0.2634\n",
            "Epoch 23/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.8391 - accuracy: 0.3204 - val_loss: 1.9636 - val_accuracy: 0.2888\n",
            "Epoch 24/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.8288 - accuracy: 0.3246 - val_loss: 1.8688 - val_accuracy: 0.3129\n",
            "Epoch 25/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.8287 - accuracy: 0.3182 - val_loss: 1.9301 - val_accuracy: 0.3025\n",
            "Epoch 26/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.8306 - accuracy: 0.3221 - val_loss: 1.9876 - val_accuracy: 0.2875\n",
            "Epoch 27/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.8231 - accuracy: 0.3262 - val_loss: 1.8953 - val_accuracy: 0.2868\n",
            "Epoch 28/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.8174 - accuracy: 0.3257 - val_loss: 1.8590 - val_accuracy: 0.3137\n",
            "Epoch 29/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.8204 - accuracy: 0.3287 - val_loss: 1.8702 - val_accuracy: 0.3094\n",
            "Epoch 30/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.8161 - accuracy: 0.3261 - val_loss: 1.9126 - val_accuracy: 0.3001\n",
            "Epoch 31/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.8175 - accuracy: 0.3289 - val_loss: 1.8777 - val_accuracy: 0.2910\n",
            "Epoch 32/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.8188 - accuracy: 0.3253 - val_loss: 1.8238 - val_accuracy: 0.3145\n",
            "Epoch 33/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.8118 - accuracy: 0.3283 - val_loss: 1.8990 - val_accuracy: 0.3014\n",
            "Epoch 34/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.8113 - accuracy: 0.3264 - val_loss: 1.8863 - val_accuracy: 0.3074\n",
            "Epoch 35/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.8148 - accuracy: 0.3283 - val_loss: 1.8286 - val_accuracy: 0.3201\n",
            "Epoch 36/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.8132 - accuracy: 0.3285 - val_loss: 1.8481 - val_accuracy: 0.3119\n",
            "Epoch 37/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.8096 - accuracy: 0.3286 - val_loss: 1.9284 - val_accuracy: 0.2973\n",
            "Epoch 38/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.8069 - accuracy: 0.3297 - val_loss: 1.8823 - val_accuracy: 0.3112\n",
            "Epoch 39/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.8022 - accuracy: 0.3319 - val_loss: 1.9488 - val_accuracy: 0.2890\n",
            "Epoch 40/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.8056 - accuracy: 0.3290 - val_loss: 1.8311 - val_accuracy: 0.3153\n",
            "Epoch 41/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.8065 - accuracy: 0.3279 - val_loss: 1.8794 - val_accuracy: 0.3012\n",
            "Epoch 42/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.8055 - accuracy: 0.3298 - val_loss: 1.8529 - val_accuracy: 0.3309\n",
            "Epoch 43/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.8032 - accuracy: 0.3296 - val_loss: 1.8255 - val_accuracy: 0.3308\n",
            "Epoch 44/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.8020 - accuracy: 0.3302 - val_loss: 1.8133 - val_accuracy: 0.3236\n",
            "Epoch 45/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.7987 - accuracy: 0.3305 - val_loss: 1.7983 - val_accuracy: 0.3262\n",
            "Epoch 46/50\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.8023 - accuracy: 0.3312 - val_loss: 1.9147 - val_accuracy: 0.2828\n",
            "Epoch 47/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.8011 - accuracy: 0.3308 - val_loss: 1.9107 - val_accuracy: 0.2967\n",
            "Epoch 48/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.7970 - accuracy: 0.3310 - val_loss: 1.9550 - val_accuracy: 0.2985\n",
            "Epoch 49/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.7932 - accuracy: 0.3324 - val_loss: 1.8081 - val_accuracy: 0.3315\n",
            "Epoch 50/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.7938 - accuracy: 0.3351 - val_loss: 1.8441 - val_accuracy: 0.3128\n",
            "Experiment with LR=0.01, optimizer:Adagrad\n",
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 3072)]            0         \n",
            "                                                                 \n",
            " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
            "                                                                 \n",
            " hidden_layer2 (Dense)       (None, 256)               131328    \n",
            "                                                                 \n",
            " hidden_layer3 (Dense)       (None, 128)               32896     \n",
            "                                                                 \n",
            " output (Dense)              (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,738,890\n",
            "Trainable params: 1,738,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.9936 - accuracy: 0.2834 - val_loss: 1.8843 - val_accuracy: 0.3360\n",
            "Epoch 2/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.8182 - accuracy: 0.3547 - val_loss: 1.8562 - val_accuracy: 0.3263\n",
            "Epoch 3/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.7366 - accuracy: 0.3840 - val_loss: 1.8622 - val_accuracy: 0.3394\n",
            "Epoch 4/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.6807 - accuracy: 0.4043 - val_loss: 1.7248 - val_accuracy: 0.3741\n",
            "Epoch 5/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.6392 - accuracy: 0.4199 - val_loss: 1.7100 - val_accuracy: 0.3867\n",
            "Epoch 6/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.6070 - accuracy: 0.4315 - val_loss: 1.6313 - val_accuracy: 0.4149\n",
            "Epoch 7/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.5712 - accuracy: 0.4452 - val_loss: 1.6714 - val_accuracy: 0.4018\n",
            "Epoch 8/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.5470 - accuracy: 0.4552 - val_loss: 1.5428 - val_accuracy: 0.4497\n",
            "Epoch 9/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.5251 - accuracy: 0.4614 - val_loss: 1.6658 - val_accuracy: 0.4043\n",
            "Epoch 10/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.5040 - accuracy: 0.4699 - val_loss: 1.5466 - val_accuracy: 0.4438\n",
            "Epoch 11/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.4720 - accuracy: 0.4800 - val_loss: 1.5901 - val_accuracy: 0.4277\n",
            "Epoch 12/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.4584 - accuracy: 0.4854 - val_loss: 1.5226 - val_accuracy: 0.4635\n",
            "Epoch 13/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.4368 - accuracy: 0.4954 - val_loss: 1.6864 - val_accuracy: 0.4078\n",
            "Epoch 14/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.4272 - accuracy: 0.4995 - val_loss: 1.6086 - val_accuracy: 0.4277\n",
            "Epoch 15/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.4068 - accuracy: 0.5038 - val_loss: 1.8872 - val_accuracy: 0.3495\n",
            "Epoch 16/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.3960 - accuracy: 0.5088 - val_loss: 1.4261 - val_accuracy: 0.4954\n",
            "Epoch 17/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.3777 - accuracy: 0.5135 - val_loss: 1.4964 - val_accuracy: 0.4706\n",
            "Epoch 18/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.3601 - accuracy: 0.5197 - val_loss: 1.4566 - val_accuracy: 0.4743\n",
            "Epoch 19/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.3482 - accuracy: 0.5257 - val_loss: 1.4331 - val_accuracy: 0.4936\n",
            "Epoch 20/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.3344 - accuracy: 0.5309 - val_loss: 1.5609 - val_accuracy: 0.4412\n",
            "Epoch 21/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.3181 - accuracy: 0.5350 - val_loss: 1.4816 - val_accuracy: 0.4676\n",
            "Epoch 22/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.3068 - accuracy: 0.5409 - val_loss: 1.4127 - val_accuracy: 0.4973\n",
            "Epoch 23/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.2951 - accuracy: 0.5467 - val_loss: 1.4371 - val_accuracy: 0.4818\n",
            "Epoch 24/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.2870 - accuracy: 0.5475 - val_loss: 1.5834 - val_accuracy: 0.4507\n",
            "Epoch 25/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.2730 - accuracy: 0.5531 - val_loss: 1.3692 - val_accuracy: 0.5117\n",
            "Epoch 26/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.2581 - accuracy: 0.5583 - val_loss: 1.4016 - val_accuracy: 0.5025\n",
            "Epoch 27/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.2457 - accuracy: 0.5622 - val_loss: 1.4573 - val_accuracy: 0.4854\n",
            "Epoch 28/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.2398 - accuracy: 0.5656 - val_loss: 1.3844 - val_accuracy: 0.5133\n",
            "Epoch 29/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.2299 - accuracy: 0.5690 - val_loss: 1.4131 - val_accuracy: 0.5041\n",
            "Epoch 30/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.2191 - accuracy: 0.5728 - val_loss: 1.3541 - val_accuracy: 0.5207\n",
            "Epoch 31/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.2037 - accuracy: 0.5767 - val_loss: 1.4510 - val_accuracy: 0.4912\n",
            "Epoch 32/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.1924 - accuracy: 0.5817 - val_loss: 1.4521 - val_accuracy: 0.4904\n",
            "Epoch 33/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.1867 - accuracy: 0.5857 - val_loss: 1.4035 - val_accuracy: 0.5036\n",
            "Epoch 34/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.1727 - accuracy: 0.5902 - val_loss: 1.6648 - val_accuracy: 0.4252\n",
            "Epoch 35/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1609 - accuracy: 0.5943 - val_loss: 1.4168 - val_accuracy: 0.4951\n",
            "Epoch 36/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.1536 - accuracy: 0.5944 - val_loss: 1.3508 - val_accuracy: 0.5192\n",
            "Epoch 37/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.1435 - accuracy: 0.5991 - val_loss: 1.4995 - val_accuracy: 0.4825\n",
            "Epoch 38/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.1283 - accuracy: 0.6063 - val_loss: 1.5258 - val_accuracy: 0.4618\n",
            "Epoch 39/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.1224 - accuracy: 0.6080 - val_loss: 1.3562 - val_accuracy: 0.5151\n",
            "Epoch 40/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.1121 - accuracy: 0.6130 - val_loss: 1.3723 - val_accuracy: 0.5157\n",
            "Epoch 41/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.1039 - accuracy: 0.6143 - val_loss: 1.3822 - val_accuracy: 0.5123\n",
            "Epoch 42/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.0979 - accuracy: 0.6171 - val_loss: 1.3920 - val_accuracy: 0.5077\n",
            "Epoch 43/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.0841 - accuracy: 0.6227 - val_loss: 1.4240 - val_accuracy: 0.4969\n",
            "Epoch 44/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.0790 - accuracy: 0.6232 - val_loss: 1.3240 - val_accuracy: 0.5313\n",
            "Epoch 45/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.0658 - accuracy: 0.6279 - val_loss: 1.3519 - val_accuracy: 0.5195\n",
            "Epoch 46/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.0597 - accuracy: 0.6316 - val_loss: 1.4616 - val_accuracy: 0.5002\n",
            "Epoch 47/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.0491 - accuracy: 0.6330 - val_loss: 1.4652 - val_accuracy: 0.4924\n",
            "Epoch 48/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.0371 - accuracy: 0.6401 - val_loss: 1.3657 - val_accuracy: 0.5259\n",
            "Epoch 49/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.0308 - accuracy: 0.6400 - val_loss: 1.4544 - val_accuracy: 0.4976\n",
            "Epoch 50/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.0196 - accuracy: 0.6461 - val_loss: 1.3766 - val_accuracy: 0.5219\n",
            "Experiment with LR=0.001, optimizer:SGD\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 3072)]            0         \n",
            "                                                                 \n",
            " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
            "                                                                 \n",
            " hidden_layer2 (Dense)       (None, 256)               131328    \n",
            "                                                                 \n",
            " hidden_layer3 (Dense)       (None, 128)               32896     \n",
            "                                                                 \n",
            " output (Dense)              (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,738,890\n",
            "Trainable params: 1,738,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 2.0237 - accuracy: 0.2754 - val_loss: 1.8614 - val_accuracy: 0.3465\n",
            "Epoch 2/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.8026 - accuracy: 0.3685 - val_loss: 1.7600 - val_accuracy: 0.3812\n",
            "Epoch 3/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.7232 - accuracy: 0.3955 - val_loss: 1.6935 - val_accuracy: 0.4074\n",
            "Epoch 4/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.6657 - accuracy: 0.4159 - val_loss: 1.6413 - val_accuracy: 0.4255\n",
            "Epoch 5/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.6187 - accuracy: 0.4329 - val_loss: 1.6069 - val_accuracy: 0.4417\n",
            "Epoch 6/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.5784 - accuracy: 0.4478 - val_loss: 1.5715 - val_accuracy: 0.4462\n",
            "Epoch 7/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.5436 - accuracy: 0.4598 - val_loss: 1.5455 - val_accuracy: 0.4549\n",
            "Epoch 8/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.5121 - accuracy: 0.4713 - val_loss: 1.5130 - val_accuracy: 0.4688\n",
            "Epoch 9/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.4845 - accuracy: 0.4793 - val_loss: 1.5001 - val_accuracy: 0.4703\n",
            "Epoch 10/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.4593 - accuracy: 0.4875 - val_loss: 1.4896 - val_accuracy: 0.4729\n",
            "Epoch 11/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.4339 - accuracy: 0.4974 - val_loss: 1.4738 - val_accuracy: 0.4766\n",
            "Epoch 12/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.4113 - accuracy: 0.5052 - val_loss: 1.4525 - val_accuracy: 0.4876\n",
            "Epoch 13/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.3896 - accuracy: 0.5109 - val_loss: 1.4323 - val_accuracy: 0.4905\n",
            "Epoch 14/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.3699 - accuracy: 0.5178 - val_loss: 1.4409 - val_accuracy: 0.4865\n",
            "Epoch 15/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.3495 - accuracy: 0.5241 - val_loss: 1.4183 - val_accuracy: 0.4982\n",
            "Epoch 16/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.3331 - accuracy: 0.5286 - val_loss: 1.4213 - val_accuracy: 0.4944\n",
            "Epoch 17/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.3148 - accuracy: 0.5374 - val_loss: 1.4164 - val_accuracy: 0.4961\n",
            "Epoch 18/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.2953 - accuracy: 0.5438 - val_loss: 1.4085 - val_accuracy: 0.5015\n",
            "Epoch 19/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.2799 - accuracy: 0.5469 - val_loss: 1.3891 - val_accuracy: 0.5034\n",
            "Epoch 20/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.2655 - accuracy: 0.5521 - val_loss: 1.4016 - val_accuracy: 0.5020\n",
            "Epoch 21/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.2503 - accuracy: 0.5612 - val_loss: 1.3828 - val_accuracy: 0.5048\n",
            "Epoch 22/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.2350 - accuracy: 0.5642 - val_loss: 1.3935 - val_accuracy: 0.5083\n",
            "Epoch 23/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.2186 - accuracy: 0.5701 - val_loss: 1.3508 - val_accuracy: 0.5229\n",
            "Epoch 24/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.2054 - accuracy: 0.5754 - val_loss: 1.3671 - val_accuracy: 0.5181\n",
            "Epoch 25/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.1911 - accuracy: 0.5804 - val_loss: 1.3912 - val_accuracy: 0.5095\n",
            "Epoch 26/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1791 - accuracy: 0.5851 - val_loss: 1.3917 - val_accuracy: 0.5083\n",
            "Epoch 27/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.1625 - accuracy: 0.5917 - val_loss: 1.3814 - val_accuracy: 0.5114\n",
            "Epoch 28/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.1517 - accuracy: 0.5946 - val_loss: 1.3701 - val_accuracy: 0.5223\n",
            "Epoch 29/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1398 - accuracy: 0.5976 - val_loss: 1.3313 - val_accuracy: 0.5341\n",
            "Epoch 30/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1249 - accuracy: 0.6035 - val_loss: 1.4628 - val_accuracy: 0.4920\n",
            "Epoch 31/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.1067 - accuracy: 0.6113 - val_loss: 1.3332 - val_accuracy: 0.5279\n",
            "Epoch 32/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.0939 - accuracy: 0.6146 - val_loss: 1.3514 - val_accuracy: 0.5246\n",
            "Epoch 33/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.0847 - accuracy: 0.6190 - val_loss: 1.3212 - val_accuracy: 0.5329\n",
            "Epoch 34/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.0741 - accuracy: 0.6215 - val_loss: 1.3500 - val_accuracy: 0.5279\n",
            "Epoch 35/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.0587 - accuracy: 0.6296 - val_loss: 1.3213 - val_accuracy: 0.5353\n",
            "Epoch 36/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.0468 - accuracy: 0.6325 - val_loss: 1.4081 - val_accuracy: 0.5131\n",
            "Epoch 37/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.0305 - accuracy: 0.6378 - val_loss: 1.3431 - val_accuracy: 0.5364\n",
            "Epoch 38/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.0200 - accuracy: 0.6410 - val_loss: 1.4131 - val_accuracy: 0.5147\n",
            "Epoch 39/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.0040 - accuracy: 0.6474 - val_loss: 1.4126 - val_accuracy: 0.5148\n",
            "Epoch 40/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.9934 - accuracy: 0.6515 - val_loss: 1.3845 - val_accuracy: 0.5241\n",
            "Epoch 41/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.9830 - accuracy: 0.6544 - val_loss: 1.3628 - val_accuracy: 0.5237\n",
            "Epoch 42/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.9697 - accuracy: 0.6585 - val_loss: 1.3583 - val_accuracy: 0.5291\n",
            "Epoch 43/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.9556 - accuracy: 0.6637 - val_loss: 1.3527 - val_accuracy: 0.5353\n",
            "Epoch 44/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.9427 - accuracy: 0.6683 - val_loss: 1.5548 - val_accuracy: 0.4895\n",
            "Epoch 45/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.9357 - accuracy: 0.6718 - val_loss: 1.3914 - val_accuracy: 0.5193\n",
            "Epoch 46/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.9194 - accuracy: 0.6770 - val_loss: 1.3911 - val_accuracy: 0.5274\n",
            "Epoch 47/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.9067 - accuracy: 0.6848 - val_loss: 1.3807 - val_accuracy: 0.5292\n",
            "Epoch 48/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.9005 - accuracy: 0.6842 - val_loss: 1.4335 - val_accuracy: 0.5166\n",
            "Epoch 49/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.8856 - accuracy: 0.6884 - val_loss: 1.4522 - val_accuracy: 0.5182\n",
            "Epoch 50/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.8720 - accuracy: 0.6952 - val_loss: 1.3781 - val_accuracy: 0.5355\n",
            "Experiment with LR=0.001, optimizer:Adam\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 3072)]            0         \n",
            "                                                                 \n",
            " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
            "                                                                 \n",
            " hidden_layer2 (Dense)       (None, 256)               131328    \n",
            "                                                                 \n",
            " hidden_layer3 (Dense)       (None, 128)               32896     \n",
            "                                                                 \n",
            " output (Dense)              (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,738,890\n",
            "Trainable params: 1,738,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.9326 - accuracy: 0.3044 - val_loss: 1.7823 - val_accuracy: 0.3611\n",
            "Epoch 2/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.7067 - accuracy: 0.3873 - val_loss: 1.6663 - val_accuracy: 0.4092\n",
            "Epoch 3/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.6227 - accuracy: 0.4193 - val_loss: 1.6018 - val_accuracy: 0.4321\n",
            "Epoch 4/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.5521 - accuracy: 0.4470 - val_loss: 1.5417 - val_accuracy: 0.4507\n",
            "Epoch 5/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.5014 - accuracy: 0.4659 - val_loss: 1.4864 - val_accuracy: 0.4712\n",
            "Epoch 6/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.4637 - accuracy: 0.4785 - val_loss: 1.5367 - val_accuracy: 0.4558\n",
            "Epoch 7/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.4308 - accuracy: 0.4902 - val_loss: 1.4944 - val_accuracy: 0.4651\n",
            "Epoch 8/50\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.4079 - accuracy: 0.4958 - val_loss: 1.4575 - val_accuracy: 0.4829\n",
            "Epoch 9/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.3659 - accuracy: 0.5148 - val_loss: 1.4103 - val_accuracy: 0.5014\n",
            "Epoch 10/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.3545 - accuracy: 0.5175 - val_loss: 1.3901 - val_accuracy: 0.5100\n",
            "Epoch 11/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.3119 - accuracy: 0.5319 - val_loss: 1.4105 - val_accuracy: 0.5046\n",
            "Epoch 12/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.2921 - accuracy: 0.5400 - val_loss: 1.3647 - val_accuracy: 0.5112\n",
            "Epoch 13/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.2697 - accuracy: 0.5466 - val_loss: 1.4203 - val_accuracy: 0.5023\n",
            "Epoch 14/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.2476 - accuracy: 0.5544 - val_loss: 1.3751 - val_accuracy: 0.5144\n",
            "Epoch 15/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.2270 - accuracy: 0.5629 - val_loss: 1.3689 - val_accuracy: 0.5139\n",
            "Epoch 16/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.2057 - accuracy: 0.5705 - val_loss: 1.4083 - val_accuracy: 0.5120\n",
            "Epoch 17/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.1886 - accuracy: 0.5774 - val_loss: 1.3558 - val_accuracy: 0.5185\n",
            "Epoch 18/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1626 - accuracy: 0.5855 - val_loss: 1.3834 - val_accuracy: 0.5138\n",
            "Epoch 19/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.1460 - accuracy: 0.5927 - val_loss: 1.3867 - val_accuracy: 0.5126\n",
            "Epoch 20/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.1243 - accuracy: 0.5991 - val_loss: 1.3861 - val_accuracy: 0.5157\n",
            "Epoch 21/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1146 - accuracy: 0.6021 - val_loss: 1.3828 - val_accuracy: 0.5165\n",
            "Epoch 22/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.0913 - accuracy: 0.6105 - val_loss: 1.4015 - val_accuracy: 0.5155\n",
            "Epoch 23/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.0707 - accuracy: 0.6168 - val_loss: 1.4001 - val_accuracy: 0.5161\n",
            "Epoch 24/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.0517 - accuracy: 0.6228 - val_loss: 1.3852 - val_accuracy: 0.5231\n",
            "Epoch 25/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.0313 - accuracy: 0.6334 - val_loss: 1.3745 - val_accuracy: 0.5336\n",
            "Epoch 26/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.0160 - accuracy: 0.6379 - val_loss: 1.4120 - val_accuracy: 0.5221\n",
            "Epoch 27/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.9924 - accuracy: 0.6465 - val_loss: 1.3841 - val_accuracy: 0.5227\n",
            "Epoch 28/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.9791 - accuracy: 0.6518 - val_loss: 1.3706 - val_accuracy: 0.5293\n",
            "Epoch 29/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.9579 - accuracy: 0.6592 - val_loss: 1.3881 - val_accuracy: 0.5294\n",
            "Epoch 30/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.9486 - accuracy: 0.6606 - val_loss: 1.3967 - val_accuracy: 0.5365\n",
            "Epoch 31/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.9286 - accuracy: 0.6677 - val_loss: 1.4479 - val_accuracy: 0.5266\n",
            "Epoch 32/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.9080 - accuracy: 0.6763 - val_loss: 1.4125 - val_accuracy: 0.5276\n",
            "Epoch 33/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.8895 - accuracy: 0.6817 - val_loss: 1.4352 - val_accuracy: 0.5279\n",
            "Epoch 34/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.8726 - accuracy: 0.6867 - val_loss: 1.4601 - val_accuracy: 0.5313\n",
            "Epoch 35/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.8648 - accuracy: 0.6881 - val_loss: 1.4994 - val_accuracy: 0.5166\n",
            "Epoch 36/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.8459 - accuracy: 0.6971 - val_loss: 1.4773 - val_accuracy: 0.5236\n",
            "Epoch 37/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.8280 - accuracy: 0.7045 - val_loss: 1.5073 - val_accuracy: 0.5223\n",
            "Epoch 38/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.8099 - accuracy: 0.7096 - val_loss: 1.4999 - val_accuracy: 0.5279\n",
            "Epoch 39/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.7950 - accuracy: 0.7148 - val_loss: 1.5398 - val_accuracy: 0.5190\n",
            "Epoch 40/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.7714 - accuracy: 0.7241 - val_loss: 1.5969 - val_accuracy: 0.5197\n",
            "Epoch 41/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.7667 - accuracy: 0.7253 - val_loss: 1.5875 - val_accuracy: 0.5285\n",
            "Epoch 42/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.7364 - accuracy: 0.7354 - val_loss: 1.5800 - val_accuracy: 0.5185\n",
            "Epoch 43/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.7322 - accuracy: 0.7383 - val_loss: 1.6430 - val_accuracy: 0.5210\n",
            "Epoch 44/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.7194 - accuracy: 0.7440 - val_loss: 1.6364 - val_accuracy: 0.5171\n",
            "Epoch 45/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.7060 - accuracy: 0.7460 - val_loss: 1.6386 - val_accuracy: 0.5255\n",
            "Epoch 46/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.6857 - accuracy: 0.7531 - val_loss: 1.6803 - val_accuracy: 0.5190\n",
            "Epoch 47/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.6835 - accuracy: 0.7545 - val_loss: 1.7022 - val_accuracy: 0.5194\n",
            "Epoch 48/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.6603 - accuracy: 0.7642 - val_loss: 1.7286 - val_accuracy: 0.5228\n",
            "Epoch 49/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.6501 - accuracy: 0.7671 - val_loss: 1.7785 - val_accuracy: 0.5177\n",
            "Epoch 50/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.6451 - accuracy: 0.7677 - val_loss: 1.7627 - val_accuracy: 0.5173\n",
            "Experiment with LR=0.001, optimizer:RMSprop\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 3072)]            0         \n",
            "                                                                 \n",
            " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
            "                                                                 \n",
            " hidden_layer2 (Dense)       (None, 256)               131328    \n",
            "                                                                 \n",
            " hidden_layer3 (Dense)       (None, 128)               32896     \n",
            "                                                                 \n",
            " output (Dense)              (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,738,890\n",
            "Trainable params: 1,738,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 2.2737 - accuracy: 0.2100 - val_loss: 1.9976 - val_accuracy: 0.2629\n",
            "Epoch 2/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.8845 - accuracy: 0.3220 - val_loss: 1.8454 - val_accuracy: 0.3173\n",
            "Epoch 3/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.7837 - accuracy: 0.3562 - val_loss: 1.8030 - val_accuracy: 0.3323\n",
            "Epoch 4/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.7158 - accuracy: 0.3853 - val_loss: 1.7447 - val_accuracy: 0.3553\n",
            "Epoch 5/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.6591 - accuracy: 0.4071 - val_loss: 1.7091 - val_accuracy: 0.3735\n",
            "Epoch 6/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.6137 - accuracy: 0.4207 - val_loss: 1.6373 - val_accuracy: 0.4062\n",
            "Epoch 7/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.5726 - accuracy: 0.4358 - val_loss: 1.9776 - val_accuracy: 0.3328\n",
            "Epoch 8/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.5408 - accuracy: 0.4495 - val_loss: 1.6422 - val_accuracy: 0.4182\n",
            "Epoch 9/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.5080 - accuracy: 0.4598 - val_loss: 1.6021 - val_accuracy: 0.4254\n",
            "Epoch 10/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.4795 - accuracy: 0.4704 - val_loss: 1.5970 - val_accuracy: 0.4385\n",
            "Epoch 11/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.4513 - accuracy: 0.4799 - val_loss: 1.5905 - val_accuracy: 0.4298\n",
            "Epoch 12/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.4273 - accuracy: 0.4887 - val_loss: 1.6476 - val_accuracy: 0.4229\n",
            "Epoch 13/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.3997 - accuracy: 0.4983 - val_loss: 1.5077 - val_accuracy: 0.4755\n",
            "Epoch 14/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.3757 - accuracy: 0.5080 - val_loss: 1.6194 - val_accuracy: 0.4235\n",
            "Epoch 15/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.3536 - accuracy: 0.5173 - val_loss: 1.5412 - val_accuracy: 0.4541\n",
            "Epoch 16/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.3305 - accuracy: 0.5232 - val_loss: 1.6103 - val_accuracy: 0.4489\n",
            "Epoch 17/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.3128 - accuracy: 0.5315 - val_loss: 1.5687 - val_accuracy: 0.4477\n",
            "Epoch 18/50\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.2938 - accuracy: 0.5381 - val_loss: 1.5344 - val_accuracy: 0.4632\n",
            "Epoch 19/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.2699 - accuracy: 0.5468 - val_loss: 1.5279 - val_accuracy: 0.4710\n",
            "Epoch 20/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.2501 - accuracy: 0.5521 - val_loss: 1.6181 - val_accuracy: 0.4345\n",
            "Epoch 21/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.2285 - accuracy: 0.5614 - val_loss: 1.6318 - val_accuracy: 0.4586\n",
            "Epoch 22/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.2149 - accuracy: 0.5663 - val_loss: 1.5627 - val_accuracy: 0.4630\n",
            "Epoch 23/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1933 - accuracy: 0.5724 - val_loss: 1.5721 - val_accuracy: 0.4651\n",
            "Epoch 24/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1770 - accuracy: 0.5798 - val_loss: 1.4925 - val_accuracy: 0.4898\n",
            "Epoch 25/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1564 - accuracy: 0.5861 - val_loss: 1.5561 - val_accuracy: 0.4780\n",
            "Epoch 26/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1396 - accuracy: 0.5913 - val_loss: 1.7419 - val_accuracy: 0.4453\n",
            "Epoch 27/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1299 - accuracy: 0.5980 - val_loss: 1.5741 - val_accuracy: 0.4743\n",
            "Epoch 28/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1030 - accuracy: 0.6048 - val_loss: 1.5774 - val_accuracy: 0.4809\n",
            "Epoch 29/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.0892 - accuracy: 0.6101 - val_loss: 1.5972 - val_accuracy: 0.4791\n",
            "Epoch 30/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.0709 - accuracy: 0.6175 - val_loss: 1.6610 - val_accuracy: 0.4662\n",
            "Epoch 31/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.0543 - accuracy: 0.6219 - val_loss: 1.6906 - val_accuracy: 0.4615\n",
            "Epoch 32/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.0387 - accuracy: 0.6286 - val_loss: 1.7618 - val_accuracy: 0.4427\n",
            "Epoch 33/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.0230 - accuracy: 0.6345 - val_loss: 1.6063 - val_accuracy: 0.4842\n",
            "Epoch 34/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.0031 - accuracy: 0.6406 - val_loss: 1.6465 - val_accuracy: 0.4820\n",
            "Epoch 35/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.9958 - accuracy: 0.6447 - val_loss: 1.6144 - val_accuracy: 0.4819\n",
            "Epoch 36/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.9765 - accuracy: 0.6507 - val_loss: 1.6703 - val_accuracy: 0.4821\n",
            "Epoch 37/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.9617 - accuracy: 0.6558 - val_loss: 1.6884 - val_accuracy: 0.4850\n",
            "Epoch 38/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.9499 - accuracy: 0.6601 - val_loss: 1.7226 - val_accuracy: 0.4789\n",
            "Epoch 39/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.9370 - accuracy: 0.6637 - val_loss: 1.6529 - val_accuracy: 0.4972\n",
            "Epoch 40/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.9265 - accuracy: 0.6682 - val_loss: 1.7785 - val_accuracy: 0.4901\n",
            "Epoch 41/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.9126 - accuracy: 0.6737 - val_loss: 1.6698 - val_accuracy: 0.4770\n",
            "Epoch 42/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.8962 - accuracy: 0.6805 - val_loss: 1.8042 - val_accuracy: 0.4734\n",
            "Epoch 43/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.8833 - accuracy: 0.6839 - val_loss: 1.7214 - val_accuracy: 0.4918\n",
            "Epoch 44/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.8741 - accuracy: 0.6882 - val_loss: 1.8462 - val_accuracy: 0.4676\n",
            "Epoch 45/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.8613 - accuracy: 0.6894 - val_loss: 1.8951 - val_accuracy: 0.4720\n",
            "Epoch 46/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.8478 - accuracy: 0.6959 - val_loss: 1.8493 - val_accuracy: 0.4718\n",
            "Epoch 47/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.8390 - accuracy: 0.7003 - val_loss: 1.8406 - val_accuracy: 0.4831\n",
            "Epoch 48/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.8231 - accuracy: 0.7049 - val_loss: 1.8111 - val_accuracy: 0.4798\n",
            "Epoch 49/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.8170 - accuracy: 0.7057 - val_loss: 1.8296 - val_accuracy: 0.4827\n",
            "Epoch 50/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.8008 - accuracy: 0.7146 - val_loss: 1.9798 - val_accuracy: 0.4681\n",
            "Experiment with LR=0.001, optimizer:Adagrad\n",
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 3072)]            0         \n",
            "                                                                 \n",
            " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
            "                                                                 \n",
            " hidden_layer2 (Dense)       (None, 256)               131328    \n",
            "                                                                 \n",
            " hidden_layer3 (Dense)       (None, 128)               32896     \n",
            "                                                                 \n",
            " output (Dense)              (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,738,890\n",
            "Trainable params: 1,738,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "196/196 [==============================] - 2s 7ms/step - loss: 2.2044 - accuracy: 0.2056 - val_loss: 2.1196 - val_accuracy: 0.2535\n",
            "Epoch 2/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0611 - accuracy: 0.2738 - val_loss: 2.0127 - val_accuracy: 0.2862\n",
            "Epoch 3/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.9772 - accuracy: 0.3006 - val_loss: 1.9470 - val_accuracy: 0.3208\n",
            "Epoch 4/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.9247 - accuracy: 0.3229 - val_loss: 1.9090 - val_accuracy: 0.3231\n",
            "Epoch 5/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.8883 - accuracy: 0.3356 - val_loss: 1.8757 - val_accuracy: 0.3372\n",
            "Epoch 6/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.8599 - accuracy: 0.3474 - val_loss: 1.8474 - val_accuracy: 0.3465\n",
            "Epoch 7/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.8372 - accuracy: 0.3570 - val_loss: 1.8282 - val_accuracy: 0.3553\n",
            "Epoch 8/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.8176 - accuracy: 0.3639 - val_loss: 1.8124 - val_accuracy: 0.3588\n",
            "Epoch 9/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.8005 - accuracy: 0.3715 - val_loss: 1.8008 - val_accuracy: 0.3697\n",
            "Epoch 10/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.7847 - accuracy: 0.3787 - val_loss: 1.7850 - val_accuracy: 0.3734\n",
            "Epoch 11/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.7711 - accuracy: 0.3837 - val_loss: 1.7736 - val_accuracy: 0.3754\n",
            "Epoch 12/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.7571 - accuracy: 0.3894 - val_loss: 1.7591 - val_accuracy: 0.3845\n",
            "Epoch 13/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.7453 - accuracy: 0.3938 - val_loss: 1.7557 - val_accuracy: 0.3945\n",
            "Epoch 14/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.7333 - accuracy: 0.3971 - val_loss: 1.7474 - val_accuracy: 0.3897\n",
            "Epoch 15/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.7223 - accuracy: 0.4015 - val_loss: 1.7279 - val_accuracy: 0.4015\n",
            "Epoch 16/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.7116 - accuracy: 0.4059 - val_loss: 1.7288 - val_accuracy: 0.3943\n",
            "Epoch 17/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.7025 - accuracy: 0.4083 - val_loss: 1.7086 - val_accuracy: 0.4062\n",
            "Epoch 18/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.6935 - accuracy: 0.4132 - val_loss: 1.6949 - val_accuracy: 0.4114\n",
            "Epoch 19/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.6838 - accuracy: 0.4162 - val_loss: 1.6856 - val_accuracy: 0.4133\n",
            "Epoch 20/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.6758 - accuracy: 0.4201 - val_loss: 1.6911 - val_accuracy: 0.4104\n",
            "Epoch 21/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.6676 - accuracy: 0.4231 - val_loss: 1.6731 - val_accuracy: 0.4187\n",
            "Epoch 22/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.6603 - accuracy: 0.4240 - val_loss: 1.6753 - val_accuracy: 0.4155\n",
            "Epoch 23/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.6528 - accuracy: 0.4279 - val_loss: 1.6647 - val_accuracy: 0.4164\n",
            "Epoch 24/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.6457 - accuracy: 0.4286 - val_loss: 1.6502 - val_accuracy: 0.4264\n",
            "Epoch 25/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.6387 - accuracy: 0.4316 - val_loss: 1.6504 - val_accuracy: 0.4234\n",
            "Epoch 26/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.6321 - accuracy: 0.4350 - val_loss: 1.6449 - val_accuracy: 0.4220\n",
            "Epoch 27/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.6257 - accuracy: 0.4370 - val_loss: 1.6462 - val_accuracy: 0.4204\n",
            "Epoch 28/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.6195 - accuracy: 0.4388 - val_loss: 1.6333 - val_accuracy: 0.4245\n",
            "Epoch 29/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.6131 - accuracy: 0.4411 - val_loss: 1.6253 - val_accuracy: 0.4282\n",
            "Epoch 30/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.6076 - accuracy: 0.4420 - val_loss: 1.6241 - val_accuracy: 0.4344\n",
            "Epoch 31/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.6015 - accuracy: 0.4461 - val_loss: 1.6283 - val_accuracy: 0.4318\n",
            "Epoch 32/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.5961 - accuracy: 0.4473 - val_loss: 1.6146 - val_accuracy: 0.4314\n",
            "Epoch 33/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.5909 - accuracy: 0.4486 - val_loss: 1.6106 - val_accuracy: 0.4334\n",
            "Epoch 34/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.5860 - accuracy: 0.4494 - val_loss: 1.6052 - val_accuracy: 0.4350\n",
            "Epoch 35/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.5808 - accuracy: 0.4523 - val_loss: 1.6021 - val_accuracy: 0.4326\n",
            "Epoch 36/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.5749 - accuracy: 0.4551 - val_loss: 1.5915 - val_accuracy: 0.4416\n",
            "Epoch 37/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.5703 - accuracy: 0.4569 - val_loss: 1.6033 - val_accuracy: 0.4324\n",
            "Epoch 38/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.5659 - accuracy: 0.4574 - val_loss: 1.5953 - val_accuracy: 0.4407\n",
            "Epoch 39/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.5612 - accuracy: 0.4587 - val_loss: 1.5812 - val_accuracy: 0.4426\n",
            "Epoch 40/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.5572 - accuracy: 0.4604 - val_loss: 1.5803 - val_accuracy: 0.4483\n",
            "Epoch 41/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.5526 - accuracy: 0.4603 - val_loss: 1.5827 - val_accuracy: 0.4450\n",
            "Epoch 42/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.5479 - accuracy: 0.4644 - val_loss: 1.5730 - val_accuracy: 0.4444\n",
            "Epoch 43/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.5438 - accuracy: 0.4646 - val_loss: 1.5635 - val_accuracy: 0.4502\n",
            "Epoch 44/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.5399 - accuracy: 0.4658 - val_loss: 1.5673 - val_accuracy: 0.4456\n",
            "Epoch 45/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.5364 - accuracy: 0.4689 - val_loss: 1.5672 - val_accuracy: 0.4501\n",
            "Epoch 46/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.5315 - accuracy: 0.4690 - val_loss: 1.5566 - val_accuracy: 0.4515\n",
            "Epoch 47/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.5285 - accuracy: 0.4706 - val_loss: 1.5497 - val_accuracy: 0.4528\n",
            "Epoch 48/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.5243 - accuracy: 0.4720 - val_loss: 1.5465 - val_accuracy: 0.4552\n",
            "Epoch 49/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.5206 - accuracy: 0.4725 - val_loss: 1.5461 - val_accuracy: 0.4561\n",
            "Epoch 50/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.5166 - accuracy: 0.4735 - val_loss: 1.5404 - val_accuracy: 0.4597\n",
            "Experiment with LR=0.0001, optimizer:SGD\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 3072)]            0         \n",
            "                                                                 \n",
            " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
            "                                                                 \n",
            " hidden_layer2 (Dense)       (None, 256)               131328    \n",
            "                                                                 \n",
            " hidden_layer3 (Dense)       (None, 128)               32896     \n",
            "                                                                 \n",
            " output (Dense)              (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,738,890\n",
            "Trainable params: 1,738,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "196/196 [==============================] - 2s 7ms/step - loss: 2.2802 - accuracy: 0.1477 - val_loss: 2.2061 - val_accuracy: 0.2203\n",
            "Epoch 2/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.1610 - accuracy: 0.2333 - val_loss: 2.1122 - val_accuracy: 0.2581\n",
            "Epoch 3/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0780 - accuracy: 0.2658 - val_loss: 2.0407 - val_accuracy: 0.2827\n",
            "Epoch 4/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0176 - accuracy: 0.2884 - val_loss: 1.9910 - val_accuracy: 0.3024\n",
            "Epoch 5/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.9753 - accuracy: 0.3040 - val_loss: 1.9567 - val_accuracy: 0.3158\n",
            "Epoch 6/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.9434 - accuracy: 0.3154 - val_loss: 1.9266 - val_accuracy: 0.3272\n",
            "Epoch 7/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.9171 - accuracy: 0.3269 - val_loss: 1.9032 - val_accuracy: 0.3352\n",
            "Epoch 8/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.8950 - accuracy: 0.3371 - val_loss: 1.8835 - val_accuracy: 0.3439\n",
            "Epoch 9/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.8762 - accuracy: 0.3426 - val_loss: 1.8673 - val_accuracy: 0.3480\n",
            "Epoch 10/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.8591 - accuracy: 0.3512 - val_loss: 1.8502 - val_accuracy: 0.3544\n",
            "Epoch 11/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.8436 - accuracy: 0.3560 - val_loss: 1.8357 - val_accuracy: 0.3577\n",
            "Epoch 12/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.8294 - accuracy: 0.3624 - val_loss: 1.8216 - val_accuracy: 0.3634\n",
            "Epoch 13/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.8159 - accuracy: 0.3674 - val_loss: 1.8093 - val_accuracy: 0.3717\n",
            "Epoch 14/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.8030 - accuracy: 0.3708 - val_loss: 1.7976 - val_accuracy: 0.3760\n",
            "Epoch 15/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.7918 - accuracy: 0.3757 - val_loss: 1.7881 - val_accuracy: 0.3759\n",
            "Epoch 16/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.7804 - accuracy: 0.3793 - val_loss: 1.7749 - val_accuracy: 0.3815\n",
            "Epoch 17/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.7692 - accuracy: 0.3835 - val_loss: 1.7637 - val_accuracy: 0.3855\n",
            "Epoch 18/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.7591 - accuracy: 0.3868 - val_loss: 1.7555 - val_accuracy: 0.3902\n",
            "Epoch 19/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.7495 - accuracy: 0.3905 - val_loss: 1.7454 - val_accuracy: 0.3912\n",
            "Epoch 20/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.7398 - accuracy: 0.3928 - val_loss: 1.7364 - val_accuracy: 0.3957\n",
            "Epoch 21/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.7305 - accuracy: 0.3966 - val_loss: 1.7280 - val_accuracy: 0.3973\n",
            "Epoch 22/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.7215 - accuracy: 0.3999 - val_loss: 1.7198 - val_accuracy: 0.3986\n",
            "Epoch 23/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.7133 - accuracy: 0.4027 - val_loss: 1.7098 - val_accuracy: 0.4071\n",
            "Epoch 24/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.7050 - accuracy: 0.4055 - val_loss: 1.7020 - val_accuracy: 0.4088\n",
            "Epoch 25/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.6972 - accuracy: 0.4092 - val_loss: 1.6949 - val_accuracy: 0.4095\n",
            "Epoch 26/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.6904 - accuracy: 0.4112 - val_loss: 1.6882 - val_accuracy: 0.4121\n",
            "Epoch 27/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.6827 - accuracy: 0.4136 - val_loss: 1.6823 - val_accuracy: 0.4116\n",
            "Epoch 28/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.6755 - accuracy: 0.4176 - val_loss: 1.6764 - val_accuracy: 0.4136\n",
            "Epoch 29/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.6691 - accuracy: 0.4177 - val_loss: 1.6697 - val_accuracy: 0.4150\n",
            "Epoch 30/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.6629 - accuracy: 0.4206 - val_loss: 1.6637 - val_accuracy: 0.4167\n",
            "Epoch 31/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.6562 - accuracy: 0.4233 - val_loss: 1.6582 - val_accuracy: 0.4197\n",
            "Epoch 32/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.6503 - accuracy: 0.4263 - val_loss: 1.6513 - val_accuracy: 0.4235\n",
            "Epoch 33/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.6441 - accuracy: 0.4284 - val_loss: 1.6469 - val_accuracy: 0.4248\n",
            "Epoch 34/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.6384 - accuracy: 0.4305 - val_loss: 1.6403 - val_accuracy: 0.4279\n",
            "Epoch 35/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.6331 - accuracy: 0.4326 - val_loss: 1.6386 - val_accuracy: 0.4244\n",
            "Epoch 36/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.6269 - accuracy: 0.4339 - val_loss: 1.6328 - val_accuracy: 0.4278\n",
            "Epoch 37/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.6213 - accuracy: 0.4368 - val_loss: 1.6260 - val_accuracy: 0.4300\n",
            "Epoch 38/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.6163 - accuracy: 0.4374 - val_loss: 1.6233 - val_accuracy: 0.4299\n",
            "Epoch 39/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.6116 - accuracy: 0.4390 - val_loss: 1.6165 - val_accuracy: 0.4351\n",
            "Epoch 40/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.6060 - accuracy: 0.4410 - val_loss: 1.6130 - val_accuracy: 0.4353\n",
            "Epoch 41/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.6010 - accuracy: 0.4424 - val_loss: 1.6075 - val_accuracy: 0.4386\n",
            "Epoch 42/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.5961 - accuracy: 0.4442 - val_loss: 1.6035 - val_accuracy: 0.4371\n",
            "Epoch 43/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.5907 - accuracy: 0.4465 - val_loss: 1.5987 - val_accuracy: 0.4375\n",
            "Epoch 44/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.5860 - accuracy: 0.4477 - val_loss: 1.5942 - val_accuracy: 0.4388\n",
            "Epoch 45/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.5812 - accuracy: 0.4493 - val_loss: 1.5926 - val_accuracy: 0.4385\n",
            "Epoch 46/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.5775 - accuracy: 0.4509 - val_loss: 1.5862 - val_accuracy: 0.4405\n",
            "Epoch 47/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.5721 - accuracy: 0.4528 - val_loss: 1.5826 - val_accuracy: 0.4456\n",
            "Epoch 48/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.5683 - accuracy: 0.4516 - val_loss: 1.5806 - val_accuracy: 0.4440\n",
            "Epoch 49/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.5637 - accuracy: 0.4541 - val_loss: 1.5755 - val_accuracy: 0.4430\n",
            "Epoch 50/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.5595 - accuracy: 0.4561 - val_loss: 1.5722 - val_accuracy: 0.4470\n",
            "Experiment with LR=0.0001, optimizer:Adam\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 3072)]            0         \n",
            "                                                                 \n",
            " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
            "                                                                 \n",
            " hidden_layer2 (Dense)       (None, 256)               131328    \n",
            "                                                                 \n",
            " hidden_layer3 (Dense)       (None, 128)               32896     \n",
            "                                                                 \n",
            " output (Dense)              (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,738,890\n",
            "Trainable params: 1,738,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "196/196 [==============================] - 2s 7ms/step - loss: 1.9129 - accuracy: 0.3204 - val_loss: 1.7693 - val_accuracy: 0.3710\n",
            "Epoch 2/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.7140 - accuracy: 0.3986 - val_loss: 1.7077 - val_accuracy: 0.3904\n",
            "Epoch 3/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.6308 - accuracy: 0.4271 - val_loss: 1.5923 - val_accuracy: 0.4388\n",
            "Epoch 4/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.5770 - accuracy: 0.4451 - val_loss: 1.5600 - val_accuracy: 0.4508\n",
            "Epoch 5/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.5355 - accuracy: 0.4581 - val_loss: 1.5364 - val_accuracy: 0.4575\n",
            "Epoch 6/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.4937 - accuracy: 0.4745 - val_loss: 1.5141 - val_accuracy: 0.4708\n",
            "Epoch 7/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.4675 - accuracy: 0.4832 - val_loss: 1.4801 - val_accuracy: 0.4815\n",
            "Epoch 8/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.4310 - accuracy: 0.4968 - val_loss: 1.4801 - val_accuracy: 0.4751\n",
            "Epoch 9/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.4047 - accuracy: 0.5072 - val_loss: 1.4800 - val_accuracy: 0.4726\n",
            "Epoch 10/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.3823 - accuracy: 0.5137 - val_loss: 1.4468 - val_accuracy: 0.4821\n",
            "Epoch 11/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.3611 - accuracy: 0.5204 - val_loss: 1.4363 - val_accuracy: 0.4908\n",
            "Epoch 12/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.3400 - accuracy: 0.5289 - val_loss: 1.4198 - val_accuracy: 0.4919\n",
            "Epoch 13/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.3175 - accuracy: 0.5384 - val_loss: 1.4174 - val_accuracy: 0.5024\n",
            "Epoch 14/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.3009 - accuracy: 0.5425 - val_loss: 1.4130 - val_accuracy: 0.4983\n",
            "Epoch 15/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.2806 - accuracy: 0.5503 - val_loss: 1.3993 - val_accuracy: 0.4992\n",
            "Epoch 16/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.2602 - accuracy: 0.5585 - val_loss: 1.3743 - val_accuracy: 0.5142\n",
            "Epoch 17/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.2437 - accuracy: 0.5636 - val_loss: 1.3628 - val_accuracy: 0.5136\n",
            "Epoch 18/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.2287 - accuracy: 0.5698 - val_loss: 1.3537 - val_accuracy: 0.5233\n",
            "Epoch 19/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.2118 - accuracy: 0.5765 - val_loss: 1.3595 - val_accuracy: 0.5195\n",
            "Epoch 20/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.1970 - accuracy: 0.5807 - val_loss: 1.3452 - val_accuracy: 0.5230\n",
            "Epoch 21/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1766 - accuracy: 0.5863 - val_loss: 1.3869 - val_accuracy: 0.5146\n",
            "Epoch 22/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1672 - accuracy: 0.5892 - val_loss: 1.3365 - val_accuracy: 0.5277\n",
            "Epoch 23/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.1535 - accuracy: 0.5965 - val_loss: 1.3671 - val_accuracy: 0.5173\n",
            "Epoch 24/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.1346 - accuracy: 0.6014 - val_loss: 1.3461 - val_accuracy: 0.5265\n",
            "Epoch 25/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1209 - accuracy: 0.6091 - val_loss: 1.3377 - val_accuracy: 0.5314\n",
            "Epoch 26/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1100 - accuracy: 0.6127 - val_loss: 1.3277 - val_accuracy: 0.5301\n",
            "Epoch 27/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.0923 - accuracy: 0.6165 - val_loss: 1.3200 - val_accuracy: 0.5348\n",
            "Epoch 28/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.0793 - accuracy: 0.6222 - val_loss: 1.3358 - val_accuracy: 0.5311\n",
            "Epoch 29/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.0623 - accuracy: 0.6307 - val_loss: 1.3525 - val_accuracy: 0.5261\n",
            "Epoch 30/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.0548 - accuracy: 0.6309 - val_loss: 1.3208 - val_accuracy: 0.5379\n",
            "Epoch 31/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.0388 - accuracy: 0.6375 - val_loss: 1.3414 - val_accuracy: 0.5308\n",
            "Epoch 32/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.0234 - accuracy: 0.6433 - val_loss: 1.3489 - val_accuracy: 0.5318\n",
            "Epoch 33/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.0176 - accuracy: 0.6434 - val_loss: 1.3221 - val_accuracy: 0.5394\n",
            "Epoch 34/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.0033 - accuracy: 0.6486 - val_loss: 1.3233 - val_accuracy: 0.5378\n",
            "Epoch 35/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.9931 - accuracy: 0.6546 - val_loss: 1.3385 - val_accuracy: 0.5301\n",
            "Epoch 36/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.9747 - accuracy: 0.6604 - val_loss: 1.3385 - val_accuracy: 0.5343\n",
            "Epoch 37/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.9643 - accuracy: 0.6640 - val_loss: 1.3472 - val_accuracy: 0.5351\n",
            "Epoch 38/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.9529 - accuracy: 0.6679 - val_loss: 1.3157 - val_accuracy: 0.5482\n",
            "Epoch 39/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.9388 - accuracy: 0.6755 - val_loss: 1.3420 - val_accuracy: 0.5400\n",
            "Epoch 40/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.9273 - accuracy: 0.6786 - val_loss: 1.3494 - val_accuracy: 0.5344\n",
            "Epoch 41/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.9108 - accuracy: 0.6839 - val_loss: 1.3405 - val_accuracy: 0.5421\n",
            "Epoch 42/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.9031 - accuracy: 0.6863 - val_loss: 1.3769 - val_accuracy: 0.5311\n",
            "Epoch 43/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.8914 - accuracy: 0.6900 - val_loss: 1.3207 - val_accuracy: 0.5493\n",
            "Epoch 44/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.8793 - accuracy: 0.6971 - val_loss: 1.3744 - val_accuracy: 0.5346\n",
            "Epoch 45/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 0.8696 - accuracy: 0.6982 - val_loss: 1.3438 - val_accuracy: 0.5450\n",
            "Epoch 46/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.8536 - accuracy: 0.7064 - val_loss: 1.3265 - val_accuracy: 0.5526\n",
            "Epoch 47/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.8463 - accuracy: 0.7095 - val_loss: 1.3427 - val_accuracy: 0.5509\n",
            "Epoch 48/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.8301 - accuracy: 0.7119 - val_loss: 1.3753 - val_accuracy: 0.5365\n",
            "Epoch 49/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.8207 - accuracy: 0.7179 - val_loss: 1.3697 - val_accuracy: 0.5405\n",
            "Epoch 50/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.8097 - accuracy: 0.7209 - val_loss: 1.4055 - val_accuracy: 0.5368\n",
            "Experiment with LR=0.0001, optimizer:RMSprop\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 3072)]            0         \n",
            "                                                                 \n",
            " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
            "                                                                 \n",
            " hidden_layer2 (Dense)       (None, 256)               131328    \n",
            "                                                                 \n",
            " hidden_layer3 (Dense)       (None, 128)               32896     \n",
            "                                                                 \n",
            " output (Dense)              (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,738,890\n",
            "Trainable params: 1,738,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.9748 - accuracy: 0.2903 - val_loss: 1.9025 - val_accuracy: 0.3207\n",
            "Epoch 2/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.7884 - accuracy: 0.3631 - val_loss: 1.7752 - val_accuracy: 0.3570\n",
            "Epoch 3/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.7139 - accuracy: 0.3921 - val_loss: 1.7288 - val_accuracy: 0.3922\n",
            "Epoch 4/50\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.6592 - accuracy: 0.4122 - val_loss: 1.6461 - val_accuracy: 0.4208\n",
            "Epoch 5/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.6183 - accuracy: 0.4255 - val_loss: 1.7342 - val_accuracy: 0.3832\n",
            "Epoch 6/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.5830 - accuracy: 0.4400 - val_loss: 1.5921 - val_accuracy: 0.4405\n",
            "Epoch 7/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.5500 - accuracy: 0.4549 - val_loss: 1.5734 - val_accuracy: 0.4350\n",
            "Epoch 8/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.5230 - accuracy: 0.4623 - val_loss: 1.6121 - val_accuracy: 0.4332\n",
            "Epoch 9/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.4977 - accuracy: 0.4717 - val_loss: 1.6694 - val_accuracy: 0.4021\n",
            "Epoch 10/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.4728 - accuracy: 0.4792 - val_loss: 1.5515 - val_accuracy: 0.4456\n",
            "Epoch 11/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.4486 - accuracy: 0.4882 - val_loss: 1.5243 - val_accuracy: 0.4609\n",
            "Epoch 12/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.4272 - accuracy: 0.4970 - val_loss: 1.5027 - val_accuracy: 0.4652\n",
            "Epoch 13/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.4080 - accuracy: 0.5036 - val_loss: 1.4809 - val_accuracy: 0.4674\n",
            "Epoch 14/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.3909 - accuracy: 0.5097 - val_loss: 1.5044 - val_accuracy: 0.4684\n",
            "Epoch 15/50\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.3736 - accuracy: 0.5182 - val_loss: 1.4816 - val_accuracy: 0.4694\n",
            "Epoch 16/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.3577 - accuracy: 0.5231 - val_loss: 1.4314 - val_accuracy: 0.4927\n",
            "Epoch 17/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.3396 - accuracy: 0.5281 - val_loss: 1.4234 - val_accuracy: 0.4930\n",
            "Epoch 18/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.3258 - accuracy: 0.5340 - val_loss: 1.4343 - val_accuracy: 0.4885\n",
            "Epoch 19/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.3053 - accuracy: 0.5428 - val_loss: 1.4610 - val_accuracy: 0.4787\n",
            "Epoch 20/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.2945 - accuracy: 0.5462 - val_loss: 1.4621 - val_accuracy: 0.4820\n",
            "Epoch 21/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.2780 - accuracy: 0.5525 - val_loss: 1.4312 - val_accuracy: 0.4939\n",
            "Epoch 22/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.2668 - accuracy: 0.5552 - val_loss: 1.4931 - val_accuracy: 0.4693\n",
            "Epoch 23/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.2541 - accuracy: 0.5599 - val_loss: 1.5161 - val_accuracy: 0.4664\n",
            "Epoch 24/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.2379 - accuracy: 0.5676 - val_loss: 1.4691 - val_accuracy: 0.4834\n",
            "Epoch 25/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.2251 - accuracy: 0.5728 - val_loss: 1.4373 - val_accuracy: 0.4968\n",
            "Epoch 26/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.2152 - accuracy: 0.5745 - val_loss: 1.3964 - val_accuracy: 0.5042\n",
            "Epoch 27/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.2005 - accuracy: 0.5800 - val_loss: 1.3815 - val_accuracy: 0.5064\n",
            "Epoch 28/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1912 - accuracy: 0.5839 - val_loss: 1.4689 - val_accuracy: 0.4770\n",
            "Epoch 29/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1734 - accuracy: 0.5912 - val_loss: 1.4409 - val_accuracy: 0.4978\n",
            "Epoch 30/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1625 - accuracy: 0.5947 - val_loss: 1.3430 - val_accuracy: 0.5271\n",
            "Epoch 31/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1525 - accuracy: 0.5969 - val_loss: 1.3944 - val_accuracy: 0.5117\n",
            "Epoch 32/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1418 - accuracy: 0.5995 - val_loss: 1.3785 - val_accuracy: 0.5175\n",
            "Epoch 33/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1263 - accuracy: 0.6072 - val_loss: 1.3653 - val_accuracy: 0.5166\n",
            "Epoch 34/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1153 - accuracy: 0.6122 - val_loss: 1.4412 - val_accuracy: 0.5015\n",
            "Epoch 35/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.1074 - accuracy: 0.6137 - val_loss: 1.3488 - val_accuracy: 0.5245\n",
            "Epoch 36/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.0931 - accuracy: 0.6191 - val_loss: 1.4771 - val_accuracy: 0.5014\n",
            "Epoch 37/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.0880 - accuracy: 0.6218 - val_loss: 1.4248 - val_accuracy: 0.5084\n",
            "Epoch 38/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.0737 - accuracy: 0.6267 - val_loss: 1.5503 - val_accuracy: 0.4803\n",
            "Epoch 39/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.0637 - accuracy: 0.6280 - val_loss: 1.4583 - val_accuracy: 0.4969\n",
            "Epoch 40/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.0527 - accuracy: 0.6345 - val_loss: 1.4221 - val_accuracy: 0.5140\n",
            "Epoch 41/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.0427 - accuracy: 0.6362 - val_loss: 1.4681 - val_accuracy: 0.4988\n",
            "Epoch 42/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.0296 - accuracy: 0.6403 - val_loss: 1.3336 - val_accuracy: 0.5325\n",
            "Epoch 43/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.0185 - accuracy: 0.6456 - val_loss: 1.4023 - val_accuracy: 0.5152\n",
            "Epoch 44/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.0119 - accuracy: 0.6493 - val_loss: 1.4344 - val_accuracy: 0.5135\n",
            "Epoch 45/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.9966 - accuracy: 0.6533 - val_loss: 1.4847 - val_accuracy: 0.4828\n",
            "Epoch 46/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.9922 - accuracy: 0.6563 - val_loss: 1.3827 - val_accuracy: 0.5223\n",
            "Epoch 47/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.9805 - accuracy: 0.6587 - val_loss: 1.3762 - val_accuracy: 0.5240\n",
            "Epoch 48/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.9698 - accuracy: 0.6618 - val_loss: 1.3801 - val_accuracy: 0.5232\n",
            "Epoch 49/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.9590 - accuracy: 0.6652 - val_loss: 1.4627 - val_accuracy: 0.5052\n",
            "Epoch 50/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.9509 - accuracy: 0.6697 - val_loss: 1.5375 - val_accuracy: 0.4834\n",
            "Experiment with LR=0.0001, optimizer:Adagrad\n",
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 3072)]            0         \n",
            "                                                                 \n",
            " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
            "                                                                 \n",
            " hidden_layer2 (Dense)       (None, 256)               131328    \n",
            "                                                                 \n",
            " hidden_layer3 (Dense)       (None, 128)               32896     \n",
            "                                                                 \n",
            " output (Dense)              (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,738,890\n",
            "Trainable params: 1,738,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 2.3470 - accuracy: 0.0928 - val_loss: 2.3028 - val_accuracy: 0.1041\n",
            "Epoch 2/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.2887 - accuracy: 0.1238 - val_loss: 2.2736 - val_accuracy: 0.1407\n",
            "Epoch 3/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.2641 - accuracy: 0.1569 - val_loss: 2.2519 - val_accuracy: 0.1688\n",
            "Epoch 4/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.2433 - accuracy: 0.1837 - val_loss: 2.2321 - val_accuracy: 0.2000\n",
            "Epoch 5/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.2236 - accuracy: 0.2039 - val_loss: 2.2129 - val_accuracy: 0.2194\n",
            "Epoch 6/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.2044 - accuracy: 0.2212 - val_loss: 2.1942 - val_accuracy: 0.2281\n",
            "Epoch 7/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.1858 - accuracy: 0.2284 - val_loss: 2.1766 - val_accuracy: 0.2351\n",
            "Epoch 8/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.1687 - accuracy: 0.2367 - val_loss: 2.1606 - val_accuracy: 0.2402\n",
            "Epoch 9/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.1532 - accuracy: 0.2422 - val_loss: 2.1460 - val_accuracy: 0.2469\n",
            "Epoch 10/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.1386 - accuracy: 0.2487 - val_loss: 2.1323 - val_accuracy: 0.2532\n",
            "Epoch 11/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.1249 - accuracy: 0.2533 - val_loss: 2.1193 - val_accuracy: 0.2579\n",
            "Epoch 12/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.1119 - accuracy: 0.2587 - val_loss: 2.1068 - val_accuracy: 0.2627\n",
            "Epoch 13/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.0996 - accuracy: 0.2644 - val_loss: 2.0950 - val_accuracy: 0.2681\n",
            "Epoch 14/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0878 - accuracy: 0.2680 - val_loss: 2.0837 - val_accuracy: 0.2728\n",
            "Epoch 15/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0766 - accuracy: 0.2719 - val_loss: 2.0730 - val_accuracy: 0.2766\n",
            "Epoch 16/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.0661 - accuracy: 0.2761 - val_loss: 2.0630 - val_accuracy: 0.2775\n",
            "Epoch 17/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.0561 - accuracy: 0.2786 - val_loss: 2.0532 - val_accuracy: 0.2829\n",
            "Epoch 18/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0465 - accuracy: 0.2830 - val_loss: 2.0440 - val_accuracy: 0.2871\n",
            "Epoch 19/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0374 - accuracy: 0.2854 - val_loss: 2.0354 - val_accuracy: 0.2887\n",
            "Epoch 20/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0287 - accuracy: 0.2887 - val_loss: 2.0269 - val_accuracy: 0.2928\n",
            "Epoch 21/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0205 - accuracy: 0.2914 - val_loss: 2.0190 - val_accuracy: 0.2958\n",
            "Epoch 22/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.0126 - accuracy: 0.2947 - val_loss: 2.0114 - val_accuracy: 0.2974\n",
            "Epoch 23/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.0051 - accuracy: 0.2969 - val_loss: 2.0043 - val_accuracy: 0.3003\n",
            "Epoch 24/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.9980 - accuracy: 0.2986 - val_loss: 1.9975 - val_accuracy: 0.3026\n",
            "Epoch 25/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.9913 - accuracy: 0.3006 - val_loss: 1.9909 - val_accuracy: 0.3031\n",
            "Epoch 26/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.9847 - accuracy: 0.3035 - val_loss: 1.9846 - val_accuracy: 0.3041\n",
            "Epoch 27/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.9785 - accuracy: 0.3056 - val_loss: 1.9786 - val_accuracy: 0.3056\n",
            "Epoch 28/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.9726 - accuracy: 0.3074 - val_loss: 1.9728 - val_accuracy: 0.3100\n",
            "Epoch 29/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.9668 - accuracy: 0.3104 - val_loss: 1.9672 - val_accuracy: 0.3115\n",
            "Epoch 30/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.9613 - accuracy: 0.3125 - val_loss: 1.9619 - val_accuracy: 0.3134\n",
            "Epoch 31/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.9561 - accuracy: 0.3145 - val_loss: 1.9569 - val_accuracy: 0.3160\n",
            "Epoch 32/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.9511 - accuracy: 0.3160 - val_loss: 1.9520 - val_accuracy: 0.3153\n",
            "Epoch 33/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.9463 - accuracy: 0.3173 - val_loss: 1.9474 - val_accuracy: 0.3181\n",
            "Epoch 34/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.9416 - accuracy: 0.3187 - val_loss: 1.9429 - val_accuracy: 0.3184\n",
            "Epoch 35/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.9372 - accuracy: 0.3208 - val_loss: 1.9385 - val_accuracy: 0.3232\n",
            "Epoch 36/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.9329 - accuracy: 0.3228 - val_loss: 1.9343 - val_accuracy: 0.3231\n",
            "Epoch 37/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.9287 - accuracy: 0.3243 - val_loss: 1.9303 - val_accuracy: 0.3236\n",
            "Epoch 38/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.9247 - accuracy: 0.3249 - val_loss: 1.9263 - val_accuracy: 0.3249\n",
            "Epoch 39/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.9209 - accuracy: 0.3269 - val_loss: 1.9225 - val_accuracy: 0.3267\n",
            "Epoch 40/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.9171 - accuracy: 0.3280 - val_loss: 1.9188 - val_accuracy: 0.3283\n",
            "Epoch 41/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.9135 - accuracy: 0.3293 - val_loss: 1.9154 - val_accuracy: 0.3287\n",
            "Epoch 42/50\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.9100 - accuracy: 0.3309 - val_loss: 1.9118 - val_accuracy: 0.3289\n",
            "Epoch 43/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.9066 - accuracy: 0.3323 - val_loss: 1.9085 - val_accuracy: 0.3320\n",
            "Epoch 44/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.9033 - accuracy: 0.3337 - val_loss: 1.9051 - val_accuracy: 0.3334\n",
            "Epoch 45/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.9000 - accuracy: 0.3350 - val_loss: 1.9020 - val_accuracy: 0.3349\n",
            "Epoch 46/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.8969 - accuracy: 0.3367 - val_loss: 1.8990 - val_accuracy: 0.3369\n",
            "Epoch 47/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.8938 - accuracy: 0.3369 - val_loss: 1.8960 - val_accuracy: 0.3378\n",
            "Epoch 48/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.8908 - accuracy: 0.3382 - val_loss: 1.8931 - val_accuracy: 0.3384\n",
            "Epoch 49/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.8880 - accuracy: 0.3390 - val_loss: 1.8903 - val_accuracy: 0.3402\n",
            "Epoch 50/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.8852 - accuracy: 0.3403 - val_loss: 1.8875 - val_accuracy: 0.3410\n",
            "Experiment with LR=1e-05, optimizer:SGD\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 3072)]            0         \n",
            "                                                                 \n",
            " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
            "                                                                 \n",
            " hidden_layer2 (Dense)       (None, 256)               131328    \n",
            "                                                                 \n",
            " hidden_layer3 (Dense)       (None, 128)               32896     \n",
            "                                                                 \n",
            " output (Dense)              (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,738,890\n",
            "Trainable params: 1,738,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.3056 - accuracy: 0.1292 - val_loss: 2.2861 - val_accuracy: 0.1368\n",
            "Epoch 2/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.2712 - accuracy: 0.1479 - val_loss: 2.2629 - val_accuracy: 0.1595\n",
            "Epoch 3/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.2514 - accuracy: 0.1755 - val_loss: 2.2451 - val_accuracy: 0.1855\n",
            "Epoch 4/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.2349 - accuracy: 0.1928 - val_loss: 2.2298 - val_accuracy: 0.1995\n",
            "Epoch 5/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.2206 - accuracy: 0.2056 - val_loss: 2.2162 - val_accuracy: 0.2108\n",
            "Epoch 6/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.2076 - accuracy: 0.2133 - val_loss: 2.2038 - val_accuracy: 0.2200\n",
            "Epoch 7/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.1956 - accuracy: 0.2237 - val_loss: 2.1921 - val_accuracy: 0.2265\n",
            "Epoch 8/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.1844 - accuracy: 0.2298 - val_loss: 2.1811 - val_accuracy: 0.2321\n",
            "Epoch 9/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.1737 - accuracy: 0.2339 - val_loss: 2.1708 - val_accuracy: 0.2371\n",
            "Epoch 10/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.1637 - accuracy: 0.2392 - val_loss: 2.1609 - val_accuracy: 0.2407\n",
            "Epoch 11/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.1539 - accuracy: 0.2429 - val_loss: 2.1513 - val_accuracy: 0.2453\n",
            "Epoch 12/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.1445 - accuracy: 0.2463 - val_loss: 2.1420 - val_accuracy: 0.2487\n",
            "Epoch 13/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.1354 - accuracy: 0.2491 - val_loss: 2.1329 - val_accuracy: 0.2517\n",
            "Epoch 14/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.1264 - accuracy: 0.2527 - val_loss: 2.1240 - val_accuracy: 0.2534\n",
            "Epoch 15/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.1175 - accuracy: 0.2571 - val_loss: 2.1150 - val_accuracy: 0.2555\n",
            "Epoch 16/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.1086 - accuracy: 0.2598 - val_loss: 2.1060 - val_accuracy: 0.2565\n",
            "Epoch 17/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.0999 - accuracy: 0.2621 - val_loss: 2.0973 - val_accuracy: 0.2602\n",
            "Epoch 18/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0914 - accuracy: 0.2667 - val_loss: 2.0888 - val_accuracy: 0.2619\n",
            "Epoch 19/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.0832 - accuracy: 0.2681 - val_loss: 2.0809 - val_accuracy: 0.2654\n",
            "Epoch 20/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.0755 - accuracy: 0.2710 - val_loss: 2.0732 - val_accuracy: 0.2685\n",
            "Epoch 21/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.0680 - accuracy: 0.2728 - val_loss: 2.0659 - val_accuracy: 0.2702\n",
            "Epoch 22/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.0608 - accuracy: 0.2762 - val_loss: 2.0588 - val_accuracy: 0.2743\n",
            "Epoch 23/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.0538 - accuracy: 0.2791 - val_loss: 2.0520 - val_accuracy: 0.2759\n",
            "Epoch 24/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.0472 - accuracy: 0.2813 - val_loss: 2.0455 - val_accuracy: 0.2776\n",
            "Epoch 25/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.0407 - accuracy: 0.2841 - val_loss: 2.0392 - val_accuracy: 0.2817\n",
            "Epoch 26/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.0345 - accuracy: 0.2862 - val_loss: 2.0331 - val_accuracy: 0.2845\n",
            "Epoch 27/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.0284 - accuracy: 0.2887 - val_loss: 2.0271 - val_accuracy: 0.2865\n",
            "Epoch 28/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.0226 - accuracy: 0.2915 - val_loss: 2.0214 - val_accuracy: 0.2887\n",
            "Epoch 29/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0169 - accuracy: 0.2935 - val_loss: 2.0158 - val_accuracy: 0.2902\n",
            "Epoch 30/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0115 - accuracy: 0.2953 - val_loss: 2.0104 - val_accuracy: 0.2916\n",
            "Epoch 31/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.0061 - accuracy: 0.2978 - val_loss: 2.0052 - val_accuracy: 0.2949\n",
            "Epoch 32/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.0010 - accuracy: 0.3001 - val_loss: 2.0001 - val_accuracy: 0.2978\n",
            "Epoch 33/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.9960 - accuracy: 0.3020 - val_loss: 1.9951 - val_accuracy: 0.2981\n",
            "Epoch 34/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.9911 - accuracy: 0.3022 - val_loss: 1.9904 - val_accuracy: 0.3022\n",
            "Epoch 35/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.9865 - accuracy: 0.3055 - val_loss: 1.9858 - val_accuracy: 0.3044\n",
            "Epoch 36/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.9819 - accuracy: 0.3061 - val_loss: 1.9812 - val_accuracy: 0.3059\n",
            "Epoch 37/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.9774 - accuracy: 0.3098 - val_loss: 1.9768 - val_accuracy: 0.3080\n",
            "Epoch 38/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.9730 - accuracy: 0.3102 - val_loss: 1.9725 - val_accuracy: 0.3110\n",
            "Epoch 39/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.9688 - accuracy: 0.3127 - val_loss: 1.9683 - val_accuracy: 0.3122\n",
            "Epoch 40/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.9647 - accuracy: 0.3146 - val_loss: 1.9643 - val_accuracy: 0.3138\n",
            "Epoch 41/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.9606 - accuracy: 0.3175 - val_loss: 1.9603 - val_accuracy: 0.3136\n",
            "Epoch 42/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.9567 - accuracy: 0.3177 - val_loss: 1.9563 - val_accuracy: 0.3163\n",
            "Epoch 43/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.9528 - accuracy: 0.3195 - val_loss: 1.9526 - val_accuracy: 0.3160\n",
            "Epoch 44/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.9490 - accuracy: 0.3205 - val_loss: 1.9489 - val_accuracy: 0.3203\n",
            "Epoch 45/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.9453 - accuracy: 0.3223 - val_loss: 1.9453 - val_accuracy: 0.3205\n",
            "Epoch 46/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.9417 - accuracy: 0.3242 - val_loss: 1.9417 - val_accuracy: 0.3217\n",
            "Epoch 47/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.9381 - accuracy: 0.3244 - val_loss: 1.9383 - val_accuracy: 0.3238\n",
            "Epoch 48/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.9347 - accuracy: 0.3275 - val_loss: 1.9349 - val_accuracy: 0.3256\n",
            "Epoch 49/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.9313 - accuracy: 0.3280 - val_loss: 1.9316 - val_accuracy: 0.3258\n",
            "Epoch 50/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.9280 - accuracy: 0.3294 - val_loss: 1.9284 - val_accuracy: 0.3253\n",
            "Experiment with LR=1e-05, optimizer:Adam\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 3072)]            0         \n",
            "                                                                 \n",
            " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
            "                                                                 \n",
            " hidden_layer2 (Dense)       (None, 256)               131328    \n",
            "                                                                 \n",
            " hidden_layer3 (Dense)       (None, 128)               32896     \n",
            "                                                                 \n",
            " output (Dense)              (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,738,890\n",
            "Trainable params: 1,738,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 2.1375 - accuracy: 0.2337 - val_loss: 2.0140 - val_accuracy: 0.2965\n",
            "Epoch 2/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.9524 - accuracy: 0.3150 - val_loss: 1.9001 - val_accuracy: 0.3362\n",
            "Epoch 3/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.8647 - accuracy: 0.3521 - val_loss: 1.8418 - val_accuracy: 0.3618\n",
            "Epoch 4/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.8109 - accuracy: 0.3732 - val_loss: 1.7938 - val_accuracy: 0.3739\n",
            "Epoch 5/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.7739 - accuracy: 0.3844 - val_loss: 1.7591 - val_accuracy: 0.3902\n",
            "Epoch 6/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.7436 - accuracy: 0.3942 - val_loss: 1.7396 - val_accuracy: 0.3942\n",
            "Epoch 7/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.7191 - accuracy: 0.4034 - val_loss: 1.7114 - val_accuracy: 0.4077\n",
            "Epoch 8/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.6967 - accuracy: 0.4135 - val_loss: 1.6958 - val_accuracy: 0.4105\n",
            "Epoch 9/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.6779 - accuracy: 0.4188 - val_loss: 1.6761 - val_accuracy: 0.4161\n",
            "Epoch 10/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.6609 - accuracy: 0.4254 - val_loss: 1.6618 - val_accuracy: 0.4272\n",
            "Epoch 11/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.6465 - accuracy: 0.4289 - val_loss: 1.6539 - val_accuracy: 0.4167\n",
            "Epoch 12/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.6327 - accuracy: 0.4355 - val_loss: 1.6360 - val_accuracy: 0.4323\n",
            "Epoch 13/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.6192 - accuracy: 0.4403 - val_loss: 1.6261 - val_accuracy: 0.4332\n",
            "Epoch 14/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.6081 - accuracy: 0.4410 - val_loss: 1.6149 - val_accuracy: 0.4400\n",
            "Epoch 15/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.5967 - accuracy: 0.4462 - val_loss: 1.6058 - val_accuracy: 0.4402\n",
            "Epoch 16/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.5871 - accuracy: 0.4506 - val_loss: 1.5973 - val_accuracy: 0.4466\n",
            "Epoch 17/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.5761 - accuracy: 0.4532 - val_loss: 1.5888 - val_accuracy: 0.4496\n",
            "Epoch 18/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.5665 - accuracy: 0.4562 - val_loss: 1.5822 - val_accuracy: 0.4463\n",
            "Epoch 19/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.5581 - accuracy: 0.4596 - val_loss: 1.5732 - val_accuracy: 0.4532\n",
            "Epoch 20/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.5499 - accuracy: 0.4618 - val_loss: 1.5656 - val_accuracy: 0.4514\n",
            "Epoch 21/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.5413 - accuracy: 0.4650 - val_loss: 1.5600 - val_accuracy: 0.4549\n",
            "Epoch 22/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.5334 - accuracy: 0.4679 - val_loss: 1.5591 - val_accuracy: 0.4521\n",
            "Epoch 23/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.5262 - accuracy: 0.4694 - val_loss: 1.5474 - val_accuracy: 0.4608\n",
            "Epoch 24/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.5189 - accuracy: 0.4720 - val_loss: 1.5427 - val_accuracy: 0.4565\n",
            "Epoch 25/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.5122 - accuracy: 0.4752 - val_loss: 1.5350 - val_accuracy: 0.4603\n",
            "Epoch 26/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.5041 - accuracy: 0.4774 - val_loss: 1.5321 - val_accuracy: 0.4610\n",
            "Epoch 27/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.4981 - accuracy: 0.4809 - val_loss: 1.5290 - val_accuracy: 0.4631\n",
            "Epoch 28/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.4919 - accuracy: 0.4827 - val_loss: 1.5236 - val_accuracy: 0.4631\n",
            "Epoch 29/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.4851 - accuracy: 0.4825 - val_loss: 1.5149 - val_accuracy: 0.4677\n",
            "Epoch 30/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.4781 - accuracy: 0.4863 - val_loss: 1.5111 - val_accuracy: 0.4673\n",
            "Epoch 31/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.4733 - accuracy: 0.4889 - val_loss: 1.5073 - val_accuracy: 0.4687\n",
            "Epoch 32/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.4674 - accuracy: 0.4911 - val_loss: 1.5025 - val_accuracy: 0.4730\n",
            "Epoch 33/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 1.4610 - accuracy: 0.4926 - val_loss: 1.4966 - val_accuracy: 0.4732\n",
            "Epoch 34/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.4555 - accuracy: 0.4956 - val_loss: 1.4949 - val_accuracy: 0.4722\n",
            "Epoch 35/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.4497 - accuracy: 0.4966 - val_loss: 1.4936 - val_accuracy: 0.4747\n",
            "Epoch 36/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.4452 - accuracy: 0.4996 - val_loss: 1.4926 - val_accuracy: 0.4738\n",
            "Epoch 37/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.4401 - accuracy: 0.5006 - val_loss: 1.4807 - val_accuracy: 0.4804\n",
            "Epoch 38/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.4338 - accuracy: 0.5031 - val_loss: 1.4798 - val_accuracy: 0.4792\n",
            "Epoch 39/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.4285 - accuracy: 0.5052 - val_loss: 1.4757 - val_accuracy: 0.4792\n",
            "Epoch 40/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.4239 - accuracy: 0.5053 - val_loss: 1.4719 - val_accuracy: 0.4825\n",
            "Epoch 41/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.4185 - accuracy: 0.5067 - val_loss: 1.4741 - val_accuracy: 0.4838\n",
            "Epoch 42/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.4149 - accuracy: 0.5097 - val_loss: 1.4644 - val_accuracy: 0.4819\n",
            "Epoch 43/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.4090 - accuracy: 0.5131 - val_loss: 1.4599 - val_accuracy: 0.4845\n",
            "Epoch 44/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.4037 - accuracy: 0.5147 - val_loss: 1.4578 - val_accuracy: 0.4858\n",
            "Epoch 45/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.3993 - accuracy: 0.5143 - val_loss: 1.4544 - val_accuracy: 0.4867\n",
            "Epoch 46/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.3950 - accuracy: 0.5177 - val_loss: 1.4534 - val_accuracy: 0.4843\n",
            "Epoch 47/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.3910 - accuracy: 0.5179 - val_loss: 1.4486 - val_accuracy: 0.4899\n",
            "Epoch 48/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.3855 - accuracy: 0.5206 - val_loss: 1.4493 - val_accuracy: 0.4891\n",
            "Epoch 49/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.3805 - accuracy: 0.5215 - val_loss: 1.4415 - val_accuracy: 0.4882\n",
            "Epoch 50/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.3760 - accuracy: 0.5238 - val_loss: 1.4374 - val_accuracy: 0.4921\n",
            "Experiment with LR=1e-05, optimizer:RMSprop\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 3072)]            0         \n",
            "                                                                 \n",
            " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
            "                                                                 \n",
            " hidden_layer2 (Dense)       (None, 256)               131328    \n",
            "                                                                 \n",
            " hidden_layer3 (Dense)       (None, 128)               32896     \n",
            "                                                                 \n",
            " output (Dense)              (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,738,890\n",
            "Trainable params: 1,738,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 2.1048 - accuracy: 0.2495 - val_loss: 1.9985 - val_accuracy: 0.2924\n",
            "Epoch 2/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.9452 - accuracy: 0.3181 - val_loss: 1.9089 - val_accuracy: 0.3256\n",
            "Epoch 3/50\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.8742 - accuracy: 0.3471 - val_loss: 1.8525 - val_accuracy: 0.3496\n",
            "Epoch 4/50\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.8274 - accuracy: 0.3630 - val_loss: 1.8108 - val_accuracy: 0.3681\n",
            "Epoch 5/50\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.7930 - accuracy: 0.3755 - val_loss: 1.7827 - val_accuracy: 0.3757\n",
            "Epoch 6/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.7659 - accuracy: 0.3858 - val_loss: 1.7579 - val_accuracy: 0.3835\n",
            "Epoch 7/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.7428 - accuracy: 0.3935 - val_loss: 1.7430 - val_accuracy: 0.3913\n",
            "Epoch 8/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.7228 - accuracy: 0.4019 - val_loss: 1.7216 - val_accuracy: 0.3986\n",
            "Epoch 9/50\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.7048 - accuracy: 0.4080 - val_loss: 1.7029 - val_accuracy: 0.4057\n",
            "Epoch 10/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.6886 - accuracy: 0.4114 - val_loss: 1.6913 - val_accuracy: 0.4049\n",
            "Epoch 11/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.6743 - accuracy: 0.4190 - val_loss: 1.6850 - val_accuracy: 0.4123\n",
            "Epoch 12/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.6605 - accuracy: 0.4237 - val_loss: 1.6650 - val_accuracy: 0.4137\n",
            "Epoch 13/50\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.6471 - accuracy: 0.4291 - val_loss: 1.6557 - val_accuracy: 0.4217\n",
            "Epoch 14/50\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.6354 - accuracy: 0.4337 - val_loss: 1.6509 - val_accuracy: 0.4176\n",
            "Epoch 15/50\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.6236 - accuracy: 0.4371 - val_loss: 1.6343 - val_accuracy: 0.4304\n",
            "Epoch 16/50\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.6128 - accuracy: 0.4405 - val_loss: 1.6285 - val_accuracy: 0.4261\n",
            "Epoch 17/50\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.6024 - accuracy: 0.4454 - val_loss: 1.6157 - val_accuracy: 0.4333\n",
            "Epoch 18/50\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.5925 - accuracy: 0.4478 - val_loss: 1.6039 - val_accuracy: 0.4378\n",
            "Epoch 19/50\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.5831 - accuracy: 0.4517 - val_loss: 1.5956 - val_accuracy: 0.4404\n",
            "Epoch 20/50\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.5738 - accuracy: 0.4548 - val_loss: 1.5964 - val_accuracy: 0.4413\n",
            "Epoch 21/50\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.5657 - accuracy: 0.4565 - val_loss: 1.5936 - val_accuracy: 0.4470\n",
            "Epoch 22/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.5565 - accuracy: 0.4610 - val_loss: 1.5729 - val_accuracy: 0.4466\n",
            "Epoch 23/50\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.5489 - accuracy: 0.4627 - val_loss: 1.5718 - val_accuracy: 0.4443\n",
            "Epoch 24/50\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.5417 - accuracy: 0.4640 - val_loss: 1.5636 - val_accuracy: 0.4489\n",
            "Epoch 25/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.5341 - accuracy: 0.4681 - val_loss: 1.5599 - val_accuracy: 0.4491\n",
            "Epoch 26/50\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.5265 - accuracy: 0.4717 - val_loss: 1.5542 - val_accuracy: 0.4497\n",
            "Epoch 27/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.5200 - accuracy: 0.4727 - val_loss: 1.5487 - val_accuracy: 0.4525\n",
            "Epoch 28/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.5134 - accuracy: 0.4754 - val_loss: 1.5440 - val_accuracy: 0.4528\n",
            "Epoch 29/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.5069 - accuracy: 0.4763 - val_loss: 1.5404 - val_accuracy: 0.4570\n",
            "Epoch 30/50\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.5005 - accuracy: 0.4796 - val_loss: 1.5275 - val_accuracy: 0.4612\n",
            "Epoch 31/50\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.4946 - accuracy: 0.4822 - val_loss: 1.5292 - val_accuracy: 0.4576\n",
            "Epoch 32/50\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.4884 - accuracy: 0.4836 - val_loss: 1.5365 - val_accuracy: 0.4525\n",
            "Epoch 33/50\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.4826 - accuracy: 0.4856 - val_loss: 1.5240 - val_accuracy: 0.4554\n",
            "Epoch 34/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.4770 - accuracy: 0.4870 - val_loss: 1.5174 - val_accuracy: 0.4595\n",
            "Epoch 35/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.4712 - accuracy: 0.4897 - val_loss: 1.5121 - val_accuracy: 0.4604\n",
            "Epoch 36/50\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.4656 - accuracy: 0.4922 - val_loss: 1.5045 - val_accuracy: 0.4682\n",
            "Epoch 37/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.4608 - accuracy: 0.4936 - val_loss: 1.5085 - val_accuracy: 0.4681\n",
            "Epoch 38/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.4549 - accuracy: 0.4953 - val_loss: 1.5147 - val_accuracy: 0.4608\n",
            "Epoch 39/50\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.4501 - accuracy: 0.4968 - val_loss: 1.4949 - val_accuracy: 0.4688\n",
            "Epoch 40/50\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.4441 - accuracy: 0.4993 - val_loss: 1.4904 - val_accuracy: 0.4730\n",
            "Epoch 41/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.4393 - accuracy: 0.5006 - val_loss: 1.4833 - val_accuracy: 0.4778\n",
            "Epoch 42/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.4348 - accuracy: 0.5033 - val_loss: 1.4848 - val_accuracy: 0.4755\n",
            "Epoch 43/50\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.4299 - accuracy: 0.5037 - val_loss: 1.4785 - val_accuracy: 0.4803\n",
            "Epoch 44/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.4251 - accuracy: 0.5052 - val_loss: 1.4796 - val_accuracy: 0.4744\n",
            "Epoch 45/50\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.4207 - accuracy: 0.5079 - val_loss: 1.4736 - val_accuracy: 0.4761\n",
            "Epoch 46/50\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.4160 - accuracy: 0.5099 - val_loss: 1.4714 - val_accuracy: 0.4730\n",
            "Epoch 47/50\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.4109 - accuracy: 0.5131 - val_loss: 1.4732 - val_accuracy: 0.4821\n",
            "Epoch 48/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 1.4066 - accuracy: 0.5118 - val_loss: 1.4744 - val_accuracy: 0.4740\n",
            "Epoch 49/50\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.4028 - accuracy: 0.5146 - val_loss: 1.4673 - val_accuracy: 0.4769\n",
            "Epoch 50/50\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.3979 - accuracy: 0.5156 - val_loss: 1.4603 - val_accuracy: 0.4841\n",
            "Experiment with LR=1e-05, optimizer:Adagrad\n",
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 3072)]            0         \n",
            "                                                                 \n",
            " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
            "                                                                 \n",
            " hidden_layer2 (Dense)       (None, 256)               131328    \n",
            "                                                                 \n",
            " hidden_layer3 (Dense)       (None, 128)               32896     \n",
            "                                                                 \n",
            " output (Dense)              (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,738,890\n",
            "Trainable params: 1,738,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 2.3501 - accuracy: 0.1001 - val_loss: 2.3396 - val_accuracy: 0.1016\n",
            "Epoch 2/50\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 2.3297 - accuracy: 0.1019 - val_loss: 2.3229 - val_accuracy: 0.1023\n",
            "Epoch 3/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.3157 - accuracy: 0.1034 - val_loss: 2.3111 - val_accuracy: 0.1033\n",
            "Epoch 4/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.3053 - accuracy: 0.1049 - val_loss: 2.3020 - val_accuracy: 0.1066\n",
            "Epoch 5/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.2971 - accuracy: 0.1077 - val_loss: 2.2948 - val_accuracy: 0.1093\n",
            "Epoch 6/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.2904 - accuracy: 0.1125 - val_loss: 2.2887 - val_accuracy: 0.1162\n",
            "Epoch 7/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.2847 - accuracy: 0.1219 - val_loss: 2.2833 - val_accuracy: 0.1265\n",
            "Epoch 8/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.2796 - accuracy: 0.1315 - val_loss: 2.2786 - val_accuracy: 0.1352\n",
            "Epoch 9/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.2750 - accuracy: 0.1424 - val_loss: 2.2742 - val_accuracy: 0.1448\n",
            "Epoch 10/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.2708 - accuracy: 0.1494 - val_loss: 2.2701 - val_accuracy: 0.1547\n",
            "Epoch 11/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.2668 - accuracy: 0.1570 - val_loss: 2.2663 - val_accuracy: 0.1589\n",
            "Epoch 12/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.2631 - accuracy: 0.1634 - val_loss: 2.2626 - val_accuracy: 0.1625\n",
            "Epoch 13/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.2595 - accuracy: 0.1685 - val_loss: 2.2592 - val_accuracy: 0.1681\n",
            "Epoch 14/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.2561 - accuracy: 0.1727 - val_loss: 2.2558 - val_accuracy: 0.1740\n",
            "Epoch 15/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.2528 - accuracy: 0.1759 - val_loss: 2.2526 - val_accuracy: 0.1769\n",
            "Epoch 16/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.2496 - accuracy: 0.1788 - val_loss: 2.2495 - val_accuracy: 0.1787\n",
            "Epoch 17/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.2465 - accuracy: 0.1798 - val_loss: 2.2464 - val_accuracy: 0.1822\n",
            "Epoch 18/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.2435 - accuracy: 0.1830 - val_loss: 2.2434 - val_accuracy: 0.1859\n",
            "Epoch 19/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.2406 - accuracy: 0.1856 - val_loss: 2.2406 - val_accuracy: 0.1865\n",
            "Epoch 20/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.2377 - accuracy: 0.1879 - val_loss: 2.2377 - val_accuracy: 0.1889\n",
            "Epoch 21/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.2349 - accuracy: 0.1907 - val_loss: 2.2350 - val_accuracy: 0.1909\n",
            "Epoch 22/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.2322 - accuracy: 0.1932 - val_loss: 2.2323 - val_accuracy: 0.1930\n",
            "Epoch 23/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.2295 - accuracy: 0.1950 - val_loss: 2.2296 - val_accuracy: 0.1936\n",
            "Epoch 24/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.2268 - accuracy: 0.1970 - val_loss: 2.2270 - val_accuracy: 0.1952\n",
            "Epoch 25/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.2242 - accuracy: 0.1984 - val_loss: 2.2245 - val_accuracy: 0.1970\n",
            "Epoch 26/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.2217 - accuracy: 0.2003 - val_loss: 2.2219 - val_accuracy: 0.1975\n",
            "Epoch 27/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.2192 - accuracy: 0.2018 - val_loss: 2.2195 - val_accuracy: 0.1990\n",
            "Epoch 28/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.2167 - accuracy: 0.2034 - val_loss: 2.2170 - val_accuracy: 0.2008\n",
            "Epoch 29/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.2143 - accuracy: 0.2050 - val_loss: 2.2146 - val_accuracy: 0.2036\n",
            "Epoch 30/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.2118 - accuracy: 0.2068 - val_loss: 2.2122 - val_accuracy: 0.2055\n",
            "Epoch 31/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.2095 - accuracy: 0.2086 - val_loss: 2.2098 - val_accuracy: 0.2067\n",
            "Epoch 32/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.2071 - accuracy: 0.2100 - val_loss: 2.2075 - val_accuracy: 0.2076\n",
            "Epoch 33/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.2048 - accuracy: 0.2114 - val_loss: 2.2052 - val_accuracy: 0.2090\n",
            "Epoch 34/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.2025 - accuracy: 0.2128 - val_loss: 2.2029 - val_accuracy: 0.2099\n",
            "Epoch 35/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.2002 - accuracy: 0.2141 - val_loss: 2.2007 - val_accuracy: 0.2114\n",
            "Epoch 36/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.1979 - accuracy: 0.2150 - val_loss: 2.1985 - val_accuracy: 0.2119\n",
            "Epoch 37/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.1957 - accuracy: 0.2166 - val_loss: 2.1963 - val_accuracy: 0.2122\n",
            "Epoch 38/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.1935 - accuracy: 0.2174 - val_loss: 2.1941 - val_accuracy: 0.2146\n",
            "Epoch 39/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.1914 - accuracy: 0.2188 - val_loss: 2.1920 - val_accuracy: 0.2145\n",
            "Epoch 40/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.1893 - accuracy: 0.2205 - val_loss: 2.1899 - val_accuracy: 0.2151\n",
            "Epoch 41/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.1872 - accuracy: 0.2216 - val_loss: 2.1878 - val_accuracy: 0.2167\n",
            "Epoch 42/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.1851 - accuracy: 0.2228 - val_loss: 2.1858 - val_accuracy: 0.2178\n",
            "Epoch 43/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.1830 - accuracy: 0.2239 - val_loss: 2.1837 - val_accuracy: 0.2189\n",
            "Epoch 44/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.1810 - accuracy: 0.2252 - val_loss: 2.1818 - val_accuracy: 0.2203\n",
            "Epoch 45/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.1790 - accuracy: 0.2258 - val_loss: 2.1798 - val_accuracy: 0.2215\n",
            "Epoch 46/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.1771 - accuracy: 0.2265 - val_loss: 2.1779 - val_accuracy: 0.2207\n",
            "Epoch 47/50\n",
            "196/196 [==============================] - 1s 6ms/step - loss: 2.1751 - accuracy: 0.2274 - val_loss: 2.1759 - val_accuracy: 0.2222\n",
            "Epoch 48/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.1732 - accuracy: 0.2288 - val_loss: 2.1741 - val_accuracy: 0.2239\n",
            "Epoch 49/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.1714 - accuracy: 0.2302 - val_loss: 2.1722 - val_accuracy: 0.2248\n",
            "Epoch 50/50\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 2.1695 - accuracy: 0.2309 - val_loss: 2.1704 - val_accuracy: 0.2253\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import itertools\n",
        "\n",
        "results = {}\n",
        "\"\"\"\n",
        "使用迴圈，建立不同 Learning rate 的模型並訓練\n",
        "\"\"\"\n",
        "#for i, (lr, opt) in enumerate(itertools.product(LEARNING_RATE, optimizer_set)):\n",
        "for lr in LEARNING_RATE:\n",
        "    keras.backend.clear_session() # 把舊的 Graph 清掉\n",
        "    optimizer_set = [tf.keras.optimizers.SGD(learning_rate=lr, nesterov=True, momentum=0.95),\n",
        "                 tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "                 tf.keras.optimizers.RMSprop(learning_rate=lr),\n",
        "                 tf.keras.optimizers.Adagrad(learning_rate=lr)]\n",
        "    for opt in optimizer_set: \n",
        "      print(f\"Experiment with LR={lr}, optimizer:{type(opt).__name__}\")\n",
        "      model = build_mlp(input_shape=x_train.shape[1:])\n",
        "      model.summary() \n",
        "      #optimizer = tf.keras.optimizers.SGD(learning_rate=lr, nesterov=True, momentum=MOMENTUM)  \n",
        "\n",
        "      model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=opt,\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "      model.fit(x_train, y_train, \n",
        "              epochs=EPOCHS, \n",
        "              batch_size=BATCH_SIZE, \n",
        "              validation_data=(x_test, y_test), \n",
        "              shuffle=True)\n",
        "    \n",
        "      # Collect results\n",
        "      train_loss = model.history.history[\"loss\"]\n",
        "      valid_loss = model.history.history[\"val_loss\"]\n",
        "      train_acc = model.history.history[\"accuracy\"]\n",
        "      valid_acc = model.history.history[\"val_accuracy\"]\n",
        "    \n",
        "      exp_name_tag = \"exp-lr-%s-opt-%s\" % (str(lr), type(opt).__name__)\n",
        "      results[exp_name_tag] = {'train-loss': train_loss,\n",
        "                             'valid-loss': valid_loss,\n",
        "                             'train-acc': train_acc,\n",
        "                             'valid-acc': valid_acc}\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "7GSvi2CTFAWl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763
        },
        "outputId": "b4d45f5f-3a5a-48c5-d0cb-edcd33fc64c3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "color_bar = [\"r\", \"g\", \"b\", \"y\", \"m\", \"k\", \"c\", \"p\"]\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "for i, cond in enumerate(results.keys()):\n",
        "    if 'exp-lr-0.001-' in cond: \n",
        "        plt.plot(range(len(results[cond]['train-loss'])),results[cond]['train-loss'], '-', label=cond, color=color_bar[i%8])\n",
        "        plt.plot(range(len(results[cond]['valid-loss'])),results[cond]['valid-loss'], '--', label=cond, color=color_bar[i%8])\n",
        "plt.title(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "for i, cond in enumerate(results.keys()):\n",
        "    if 'exp-lr-0.001-' in cond:\n",
        "        plt.plot(range(len(results[cond]['train-acc'])),results[cond]['train-acc'], '-', label=cond, color=color_bar[i%8])\n",
        "        plt.plot(range(len(results[cond]['valid-acc'])),results[cond]['valid-acc'], '--', label=cond, color=color_bar[i%8])\n",
        "plt.title(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for k in results.keys():\n",
        "  if 'exp-lr-0.001-' in k:\n",
        "    print(k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWKze5ikw3-D",
        "outputId": "2a084848-8517-4a16-8ea4-05624a0d8050"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "exp-lr-0.001-opt-SGD\n",
            "exp-lr-0.001-opt-Adam\n",
            "exp-lr-0.001-opt-RMSprop\n",
            "exp-lr-0.001-opt-Adagrad\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 觀察結果: 以learning rate= 0.001來看: Adam及SGD優化器accuracy表現相對較好"
      ],
      "metadata": {
        "id": "6LZnTCz705sp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for k in results.keys():\n",
        "  if 'exp-lr-0.001-' in k:\n",
        "    print(results[k]['valid-acc'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvntt9if25NJ",
        "outputId": "3bf08c75-fe13-43d3-9be5-7c1348e17705"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.3465000092983246, 0.38119998574256897, 0.4074000120162964, 0.4255000054836273, 0.4417000114917755, 0.44620001316070557, 0.45489999651908875, 0.46880000829696655, 0.47029998898506165, 0.47290000319480896, 0.4765999913215637, 0.4875999987125397, 0.49050000309944153, 0.48649999499320984, 0.498199999332428, 0.4943999946117401, 0.4961000084877014, 0.5015000104904175, 0.5034000277519226, 0.5019999742507935, 0.504800021648407, 0.5083000063896179, 0.5228999853134155, 0.5181000232696533, 0.5095000267028809, 0.5083000063896179, 0.5113999843597412, 0.5223000049591064, 0.5340999960899353, 0.492000013589859, 0.527899980545044, 0.5246000289916992, 0.5328999757766724, 0.527899980545044, 0.5353000164031982, 0.5131000280380249, 0.5364000201225281, 0.5146999955177307, 0.5148000121116638, 0.5241000056266785, 0.5236999988555908, 0.5291000008583069, 0.5353000164031982, 0.4894999861717224, 0.5192999839782715, 0.527400016784668, 0.52920001745224, 0.5166000127792358, 0.5181999802589417, 0.5354999899864197]\n",
            "[0.3610999882221222, 0.4092000126838684, 0.43209999799728394, 0.4507000148296356, 0.47119998931884766, 0.45579999685287476, 0.4650999903678894, 0.4828999936580658, 0.5013999938964844, 0.5099999904632568, 0.5045999884605408, 0.5112000107765198, 0.5023000240325928, 0.5144000053405762, 0.5138999819755554, 0.5120000243186951, 0.5184999704360962, 0.5138000249862671, 0.5126000046730042, 0.5156999826431274, 0.5164999961853027, 0.515500009059906, 0.5160999894142151, 0.5231000185012817, 0.5335999727249146, 0.5220999717712402, 0.5227000117301941, 0.5292999744415283, 0.5293999910354614, 0.5364999771118164, 0.5266000032424927, 0.5275999903678894, 0.527899980545044, 0.5313000082969666, 0.5166000127792358, 0.5235999822616577, 0.5223000049591064, 0.527899980545044, 0.5189999938011169, 0.5196999907493591, 0.5285000205039978, 0.5184999704360962, 0.5210000276565552, 0.5170999765396118, 0.5254999995231628, 0.5189999938011169, 0.5194000005722046, 0.5228000283241272, 0.5177000164985657, 0.517300009727478]\n",
            "[0.2628999948501587, 0.3172999918460846, 0.33230000734329224, 0.35530000925064087, 0.3734999895095825, 0.40619999170303345, 0.3328000009059906, 0.41819998621940613, 0.4253999888896942, 0.43849998712539673, 0.42980000376701355, 0.42289999127388, 0.4754999876022339, 0.4235000014305115, 0.45410001277923584, 0.4489000141620636, 0.44769999384880066, 0.46320000290870667, 0.47099998593330383, 0.4345000088214874, 0.4586000144481659, 0.46299999952316284, 0.4650999903678894, 0.48980000615119934, 0.4779999852180481, 0.44530001282691956, 0.47429999709129333, 0.48089998960494995, 0.47909998893737793, 0.46619999408721924, 0.46149998903274536, 0.44269999861717224, 0.48420000076293945, 0.4819999933242798, 0.48190000653266907, 0.4821000099182129, 0.48500001430511475, 0.4788999855518341, 0.49720001220703125, 0.4900999963283539, 0.47699999809265137, 0.4733999967575073, 0.4918000102043152, 0.4675999879837036, 0.47200000286102295, 0.4717999994754791, 0.4830999970436096, 0.4797999858856201, 0.482699990272522, 0.46810001134872437]\n",
            "[0.2535000145435333, 0.28619998693466187, 0.3208000063896179, 0.3231000006198883, 0.33719998598098755, 0.3465000092983246, 0.35530000925064087, 0.3587999939918518, 0.36970001459121704, 0.3734000027179718, 0.37540000677108765, 0.38449999690055847, 0.3944999873638153, 0.3896999955177307, 0.40149998664855957, 0.39430001378059387, 0.40619999170303345, 0.4113999903202057, 0.4133000075817108, 0.41040000319480896, 0.4187000095844269, 0.4154999852180481, 0.4163999855518341, 0.42640000581741333, 0.42340001463890076, 0.421999990940094, 0.4203999936580658, 0.4244999885559082, 0.42820000648498535, 0.4343999922275543, 0.4318000078201294, 0.43140000104904175, 0.4334000051021576, 0.4350000023841858, 0.4325999915599823, 0.4415999948978424, 0.4323999881744385, 0.4406999945640564, 0.4426000118255615, 0.44830000400543213, 0.4449999928474426, 0.44440001249313354, 0.45019999146461487, 0.4456000030040741, 0.45010000467300415, 0.4514999985694885, 0.4528000056743622, 0.4551999866962433, 0.4560999870300293, 0.45969998836517334]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "I_j1z31A19Yz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-k-Ah8zo161u"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "D080_優化器與學習率的組合比較_作業.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}